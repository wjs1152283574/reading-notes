* 第一章 计算机系统漫游
    1. 总述
    ```
        计算机系统是由硬件和系统软件组成的,它们共同工作来运行应用程序。虽然系统的具体实现方式随着时间不断变化,但是系统内在的概念却没有改变。
        所有计算机系统都有相似的硬件和软件组件,它们又执行着相似的功能。一些程序员希望深人了解这些组件是如何工作的以及这些组件是如何影响程序的正确性和性能的,以此来提高自身的技能。
        本书便是为这些读者而写的。
    ```
    2. 信息就是位+上下文
    ```
        源程序实际上就是一个由值0和1组成的位(又称为比特)序列,8个位被组织成一组,称为字节。每个字节表示程序中的某些文本字符。
        大部分的现代计算机系统都使用AScⅡ标准来表示文本字符,这种方式实际上就是用一个唯一的单字节大小的整数值e来表示每个字符。
    ```
    3. 程序被其他程序翻译成不同的格式
    ```
        这个翻译过程可分为四个阶段完成:
        1. 预处理阶段。预处理器(cpp)根据以字符#开头的命令,修改原始的C程序。
        2. 编译阶段。编译器(ccl)将文本文件hello.i翻译咸文本文件hello.s,它包含一个汇编语言程序。
        3. 汇编阶段。接下来,汇编器(as)将he||○.S翻译成机器语言指令,把这些指令打包成一种叫做可重定位目标程.并将结果存入二进制文件.
        4. 链接阶段。请注意,hello程序调用了printf函数,它是每个C编译器都提供的标准C库中的一个函数. 
        printf函数存在于一个名为printf.o的单独的预编译好了的目标文件中,而这个文件必须以某种方式合并到我们的hello.o程序中。
        链接器(1d)就负责处理这种合并。结果就得到hello文件,它是一个可执行目标文件(或者简称为可执行文件),
        可以被加载到内存中,由系统执行。
    ```
    4. 了解编译系统如何工作是大有益处的
    ```
        对于像hello.c这样简单的程序,我们可以依靠编译系统生成正确有效的机器代码。但是,有一些重要的原因促使程序员必须知道编译系统是如何工作的。
        1. 优化程序性能。现代编译器都是成熟的工具,通常可以生成很好的代码。作为程序员,我们无须为了写出高效代码而去了解编译器的内部工作。
        2. 理解链接时出现的错误。
        3. 避兔安全漏洞。多年来,缓冲区溢出错误是造成大多数网络和Intemet服务器上安全漏洞的主要原因。
        存在这些错误是因为很少有程序员能够理解需要限制从不受信任的源接收数据的数量和格式。
        学习安全编程的第一步就是理解数据和控制信息存储在程序栈上的方式会引起的后果。
    ```
    5. 处理带读并解释储存在内存中的指令
        - 总述
        ```
            此刻,hello.c源程序已经被编译系统翻译成了可执行目标文件hel|o,并被存放在磁盘上。
            要想在Unix系统上运行该可执行文件,我们将它的文件名输人到称为shell的应用程序中:

            sheⅡ是一个命令行解释器,它输出一个提示符,等待输人一个命令行,然后执行这个命令。
            如果该命令行的第一个单词不是一个内置的shell命令,那么shell就会假设这是一个可执行文件的名字,
            它将加载并运行这个文件。所以在此例中,sheⅡ将加载并运行hello程序,然后等待程序终止. 
            hell0程序在屏幕上输出它的消息,然后终止o shell随后输出一个提示符,等待下一个输人的命令行。
        ```
        - 系统的硬件组成
        ```
            1.总线
            贯穿整个系统的是一组电子管道,称作总线,它携带信息字节并负责在各个部件间传递。
            通常总线被设计成传送定长的字节块,也就是字(word)。字中的字节数(即字长)是一个基本的系统参数,各个系统中都不尽相同。
            现在的大多数机器字长要么是4个字节(32位),要么是8个字节(64位)
            2. I/O设备
            Ⅰ/o(输人/输出)设备是系统与外部世界的联系通道。
            我们的示例系统包括四个Ⅰ/o设备:作为用户输人的键盘和鼠标,作为用户输出的显示器,以及用于长期存储数据和程序的磁盘驱动器(简单地说就是磁盘)。
            最开始,可执行程序hello就存放在磁盘上。
            3. 主存
            主存是一个临时存储设备,在处理器执行程序时,用来存放程序和程序处理的数据。
            4. 处理器
            中央处理单元(CPU),简称处理器,是解释(或执行)存储在主存中指令的引擎。
        ```
        - 高速缓存至关重要
        ```
            这个简单的示例揭示了一个重要的间题,即系统花费了大量的时间把信息从一个地方挪到另一个地方.
            hello程序的机器指令最初是存放在磁盘上,当程序加载时,它们被复制到主存;当处理器运行程序时,指令又从主存复制到处理器。
            相似地,数据串“hello,WOr|d/n#开始时在磁盘上,然后被复制到主存,最后从主存上复制到显示设备。
            从程序员的角度来看,这些复制就是开销,减慢了程序“真正”的工作。
            因此,系统设计者的一个主要目标就是使这些复制操作尽可能快地完成。

            根据机械原理,较大的存储设备要比较小的存储设备运行得慢,而快速设备的造价远高于同类的低速设备。
            比如说,一个典型系统上的磁盘驱动器可能比主存大1000倍,但是对处理器而言,
            从磁盘驱动器上读取一个字的时间开销要比从主存中读取的开销大1000万倍。

            类似地,一个典型的寄存器文件只存储几百字节的信息,而主存里可存放几十亿字节。
            然而,处理器从寄存器文件中读数据比从主存中读取几乎要快100倍。
            更麻烦的是,随着这些年半导体技术的进步,这种处理器与主存之间的差距还在持续增大。
            加快处理器的运行速度比加快主存的运行速度要容易和便宜得多。

            针对这种处理器与主存之间的差异,系统设计者采用了更小更快的存储设备,
            称为高速缓存存储器(cachememory,简称为cache或高速缓存),作为暂时的集结区域,存放处理器近期可能会需要的信息。

            本书得出的重要结论之一就是,意识到高速缓存存储器存在的应用程序员能够利用高速缓存将程序的性能提高一个数量级。
        ```
        - 存储设备形成层次结构
        ```
            在处理器和一个较大较慢的设备(例如主存)之间插人一个更小更快的存储设备(例如高速缓存)的想法已经成为一个普遍的观念。
            实际上,每个计算机系统中的存储设备都被组织成了一个存储器层次结构,在这个层次结构中,从上至下,
            设备的访问速度越来越慢、容量越来越大,并且每字节的造价也越来越便宜。寄存器文件在层次结构中位于最顶部,
            也就是第0级或记为LO.这里我们展示的是三层高速缓存Ll到L3,占据存储器层次结构的第1层到第3层。主存在第4层,以此类推。

            存储器层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存。
            因此,寄存器文件就是Ll的高速缓存,Ll是L2的高速缓存,L2是L3的高速缓存,L3是主存的高速缓存,而主存又是磁盘的高速缓存。
            在某些具有分布式文件系统的网络系统中,本地磁盘就是存储在其他系统中磁盘上的数据的高速缓存。

            正如可以运用不同的高速缓存的知识来提高程序性能一样,程序员同样可以利用对整个存储器层次结构的理解来提高程序性能。
        ```
        - 操作系统管理硬件
        ```
            让我们回到hell〇程序的例子。当shell加载和运行hello程序时,以及hello程序输出自已的消息时,
            Shell和hell〇程序都没有直接访问键盘、显示器、磁盘或者主存。
            取而代之的是,它们依靠操作系统提供的服务。我们可以把操作系统看成是应用程序和硬件之间插人的一层软件,
            所有应用程序对硬件的操作尝试都必须通过操作系统。

            1. 进程
            进程是操作系统对一个正在运行的程序的一种抽象。在一个系统上可以同时运行多个进程,
            而每个进程都好像在独占地使用硬件。而并发运行,则是说一个进程的指令和另一个进程的指令是交错执行的。
            在大多数系统中,需要运行的进程数是多于可以运行它们的CPU个数的。
            传统系统在一个时刻只能执行一个程序,而先进的多核处理器同时能够执行多个程序。
            无论是在单核还是多核系统中,一个CPU看上去都像是在并发地执行多个进程,这是通过处理器在进程间切换来实现的。
            操作系统实现这种交错执行的机制称为上下文切换。

            操作系统保持跟踪进程运行所需的所有状态信息。这种状态,也就是上下文,包括许多信息,比如PC和寄存器文件的当前值,以及主存的内容。
            在任何一个时刻,单处理器系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程时,就会进行上下文切换,
            即保存当前进程的上下文、恢复新进程的上下文,然后将控制权传递到新进程。新进程就会从它上次停止的地方开始。
            2. 线程
            尽管通常我们认为一个进程只有单一的控制流,但是在现代系统中,一个进程实际上可以由多个称为线程的执行单元组成,
            每个线程都运行在进程的上下文中,并共享同样的代码和全局数据。由于网络服务器中对并行处理的需求,
            线程成为越来越重要的编程模型,因为多线程之间比多进程之间更容易共享数据,也因为线程一般来说都比进程更高效。
            当有多处理器可用的时候,多线程也是一种使得程序可以运行得更快的方法
            3. 虚拟内存
            虚拟内存是一个抽象概念,它为每个进程提供了一个假象,即每个进程都在独占地使用主存。
            每个进程看到的内存都是一致的,称为虚拟地址空间。

            每个进程看到的虚拟地址空间由大量准确定义的区构成,每个区都有专门的功能。
            在本书的后续章节你将学到更多有关这些区的知识,但是先简单了解每一个区是非常有益的。
            我们从最低的地址开始,逐步向上介绍。
                1. 程序代码和数据 
                对所有的进程来说,代码是从同一固定地址开始,紧接着的是和C全局变量相对应的数据位置。
                代码和数据区是直接接照可执行目标文件的内容初始化的.
                2.堆
                代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始运行时就被指定了大小,
                与此不同,当调用像malloc和free这样的C标准库函数时,堆可以在运行时动态地扩展和收缩
                3.共享库。
                大约在地址空间的中间部分是一块用来存放像C标准库和数学库这样的共享库的代码和数据的区域。
                4. 栈。
                位于用户虚拟地址空间顶部的是用户栈,编译器用它来实现函数调用。
                和堆一样,用户栈在程序执行期间可以动态地扩展和收缩。
                特别地,每次我们调用一个函数时,栈就会增长;从一个函数返回时,栈就会收缩。
                5. 内核虚拟内存
                地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。
                相反,它们必须调用内核来执行这些操作。

                虚拟内存的运作需要硬件和操作系统软件之间精密复杂的交互,包括对处理器生成的每个地址的硬件翻译。
                基本思想是把一个进程虚拟内存的内容存储在磁盘上,然后用主存作为磁盘的高速缓存。
        ```
        - 文件
        ```
            文件就是字节序列,仅此而已。
            文件就是字节序列,仅此而已。每个Ⅰ/o设备,包括磁盘、键盘、显示器,甚至网络,都可以看成是文件。
            系统中的所有输人输出都是通过使用一小组称为UnixI/o的系统函数调用读写文件来实现的。
        ```
    6. 系统之间利用网络通信
    ```
        我们一直是把系统视为一个孤立的硬件和软件的集合体。实际上,现代系统经常通过网络和其他系统连接到一起。
        从一个单独的系统来看,网络可视为一个Ⅰ/o设备。
        当系统从主存复制一串字节到网络适配器时,数据流经过网络到达另一台机器,而不是比如说到达本地磁盘驱动器。
        相似地,系统可以读取从其他机器发送来的数据,并把数据复制到自已的主存.
    ```
    7. 重要主题
        - 总述
        ```
            在此,小结一下我们旋风式的系统漫游。这次讨论得出一个很重要的观点,那就是系统不仅仅只是硬件。
            系统是硬件和系统软件互相交织的集合体,它们必须共同协作以达到运行应用程序的最终目的。
            本书的余下部分会讲述硬件和软件的详细内容,通过了解这些详细内容,你可以写出更快速、更可靠和更安全的程序。
        ```
        - Amdahl定律
        ```
            律的主要观点一要想显著加速整个系统,必须提升全系统中相当大的部分的速度。
            Amdahl定律描述了改善任何过程的一般原则。除了可以用在加速计算机系统方面之外,它还可以用在公司试图降低刀片制造成本,
            或学生想要提高自已的绩点平均值等方面。也许它在计算机世界里是最有意义的,
            在这里我们常常把性能提升2倍或更高的比例因子。这么高的比例因子只有通过优化系统的大部分组件才能获得。
        ```
        - 并发和并行
        ```
            数字计算机的整个历史中,有两个需求是驱动进步的持续动力:一个是我们想要计算机做得更多,
            另一个是我们想要计算机运行得更快。当处理器能够同时做更多的事情时,这两个因素都会改进。
            我们用的术语并发(concurrency)是一个通用的概念,指一个同时具有多个活动的系统;
            而术语并行(para11elism)指的是用并发来使一个系统运行得更快。并行可以在计算机系统的多个抽象层次上运用。
            在此,我们按照系统层次结构中由高到低的顺序重点强调三个层次。
            1. 线程级并发
            构建在进程这个抽象之上,我们能够设计出同时有多个程序执行的系统,这就导致了并发。使用线程,我们甚至能够在一个进程中执行多个控制流。
            多处理器的使用可以从两方面提高系统性能。首先,它减少了在执行多个任务时模拟并发的需要。
            正如前面提到的,即使是只有一个用户使用的个人计算机也需要并发地执行多个活动。
            其次,它可以使应用程序运行得更快,当然,这必须要求程序是以多线程方式来书写的,这些线程可以并行地高效执行。
            2. 指令级并行
            在较低的抽象层次上,现代处理器可以同时执行多条指令的属性称为指令级并行。
            3. 单指令、多数据并行
            在最低层次上,许多现代处理器拥有特殊的硬件,允许一条指令产生多个可以并行执行的操作,这种方式称为单指令、多数据,即sIMD并行。
        ```
        - 计算机系统中抽象的重要性
        ```
            抽象的使用是计算机科学中最为重要的概念之一。例如,为一组函数规定一个简单的应用程序接日(API)就是一个很好的编程习惯,
            程序员无须了解它内部的工作便可以使用这些代码。不同的编程语言提供不同形式和等级的抽象支持,
            例如Java类的声明和C语言的函数原型。

            在学习操作系统时,我们介绍了三个抽象:文件是对Ⅰ/o设备的拍象,虚拟内存是对程序存储器的抽象,
            而进程是对一个正在运行的程序的抽象。我们再增加一个新的抽象:
            虚拟机,它提供对整个计算机的抽象,包括操作系统、处理器和程序。
        ```
    ###### 小结
    ```
        计算机系统是由硬件和系统软件组成的,它们共同协作以运行应用程序。
        计算机内部的信息被表示为一组组的位,它们依据上下文有不同的解释方式。
        程序被其他程序翻译成不同的形式,开始时是ASCⅡ文本,然后被编译器和链接器翻译成二进制可执行文件。

        处理器读取并解释存放在主存里的二进制指令。因为计算机花费了大量的时间在内存、 I/o设备和CPU寄存器之间复制数据,
        所以将系统中的存储设备划分成层次结构一CPU寄存器在顶部,接着是多层的硬件高速缓存存储器、 DRAM主存和磁盘存储器。
        在层次模型中,位于更高层的存储设备比低层的存储设备要更快,单位比特造价也更高。
        层次结构中较高层次的存储设备可以作为较低层次设备的高速缓存。
        通过理解和运用这种存储层次结构的知识,程序员可以优化C程序的性能。

        操作系统内核是应用程序和硬件之间的媒介。它提供三个基本的抽象:
            1)文件是对Ⅰ/o设备的抽象;
            2)虚拟内存是对主存和磁盘的抽象;
            3)进程是处理器、主存和Ⅰ/o设备的抽象。
        最后,网络提供了计算机系统之间通信的手段。从特殊系统的角度来看,网络就是一种Ⅰ/o设备。
    ```
---
### 第一部分 程序结构和执行
```
    我们对计算机系统的探索是从学习计算机本身开始的,它由处理器和存储器子系统纽成。
    在核心部分,我们需要方法来表示基本数据类型,比如整数和实数运算的近似值。
    然后,我们考虑机器级指令如何操作这样的数据,以及编译器又如何将c程序翻译成这样的指令。
    接下来,研究几种实现处理器的方法,帮助我们更好地了解硬件资源如何被用来执行指令。
    一旦理解了编译器和机器级代码,我们就能了解如何通过编写C程序以及编译它们来最大化程序的性能。
    本部分以存储器子系统的设计作为结束,这是现代计算机系统最复杂的部分之一。本书的这一部分将领着你深入了解如何表示和执行应用程序。
    你将学会一些技巧,来帮助你写出安全、可靠且充分利用计算资源的程序。
```
* 第二章 信息的表示和处理
    1. 信息存储
        - 概述
        ```
            大多数计算机使用8位的块,或者字节(byte),作为最小的可寻址的内存单位,而不是访问内存中单独的位。
            机器级程序将内存视为一个非常大的字节数组,称为虚拟内存(virtualmemory)。
            内存的每个字节都由一个唯一的数字来标识,称为它的地址(address),
            所有可能地址的集合就称为虚拟地址空间(virtualaddressspace)。
            顾名思义,这个虚拟地址空间只是一个展现给机器级程序的概念性映像。
        ```
        - 十六进制表示法
        ```
            在C语言中,以Ox或OX开头的数字常量被认为是十六进制的值。字
        ```
        - 字数据大小
        ```
            每台计算机都有一个字长(wordsize),指明指针数据的标称大小(nominalsize)。
            因为虚拟地址是以这样的一个字来编码的,所以字长决定的最重要的系统参数就是虚拟地址空间的最大大小。
            32位字长系统,对应虚拟内存一般为4GB,而64位系统则可达到16GB

            程序员应该力图使他们的程序在不同的机器和编译器上可移植。可移植性的一个方面就是使程序对不同数据类型的确切大小不敏感.

            随着64位机器的日益普及,在将这些程序移植到新机器上时,许多隐藏的对字长的依赖性就会显现出来,成为错误。
            比如,许多程序员假设一个声明为int类型的程序对象能被用来存储一个指针。这在大多数32位的机器上能正常工作,但是在一台64位的机器上却会导致问题。
        ```
        - 寻址和字节顺序
        ```
            对于跨越多字节的程序对象,我们必须建立两个规则:这个对象的地址是什么,以及在内存中如何排列这些字节。
            在几乎所有的机器上,多字节对象都被存储为连续的字节序列,对象的地址为所使用字节中最小的地址。

            对于大多数应用程序员来说,其机器所使用的字节顺序是完全不可见的。无论为哪种类型的机器所编译的程序都会得到同样的结果。
            不过有时候,字节顺序会成为问题。首先是在不同类型的机器之间通过网络传送二进制数据时,
            一个常见的问题是当小端法机器产生的数据被发送到大端法机器或者反过来时,接收程序会发现,字里的字节成了反序的。
            为了避免这类问题,网络应用程序的代码编写必须遵守已建立的关于字节顺序的规则,以确保发送方机器将它的内部表示转换成网络标准,
            而接收方机器则将网络标准转换为它的内部表示。
        ```
        - 表示字符串
        ```
            与字节顺序和字大小规则无关。因而,文本数据比二进制数据具有更强的平台独立性。
        ```
        - 表示代码
        ```
            我们发现指令编码是不同的。不同的机器类型使用不同的且不兼容的指令和编码方式。
            即使是完全一样的进程,运行在不同的操作系统上也会有不同的编码规则,因此二进制代码是不兼容的。二进制代码很少能在不同机器和操作系统组合之间移植。

            计算机系统的一个基本概念就是,从机器的角度来看,程序仅仅只是字节序列。机器没有关于原始源程序的任何信息,除了可能有些用来帮助调试的辅助表以外。
            在第3章学习机器级编程时,我们将更清楚地看到这一点.
        ```
    2. 整数表示
        - 概述
        ```
            在本节中,我们描述用位来编码整数的两种不同的方式:一种只能表示非负数,而另一种能够表示负数、零和正数。
            后面我们将会看到它们在数学属性和机器级实现方面密切相关。
            我们还会研究扩展或者收缩一个已编码整数以适应不同长度表示的效果。
        ```
        - 整型数据类型
        ```
            C语言支持多种整型数据类型--表示有限范围的整数。

            示,为这些不同的大小分配的字节数根据程序编译为32位还是64位而有所不同。
            根据字节分配,不同的大小所能表示的值的范围是不同的。这里给出来的唯一一个与机器相关的取值范围是大小指示符long的。
            大多数64位机器使用8个字节的表示,比32位机器上使用的4个字节的表示的取值范围大很多。
            
            一个很值得注意的特点是取值范围不是对称的一负数的范围比整数的范围大1.当我们考虑如何表示负数的时候,会看到为什么会这样.

        ```
        - 无符号数的编码
        ```
            我们已经看到了许多无符号运算的细微特性,尤其是有符号数到无符号数的隐式转换,会导致错误或者漏洞的方式。
            避免这类错误的一种方法就是绝不使用无符号数。实际上,除了C以外很少有语言支持无符号整数。
            很明显,这些语言的设计者认为它们带来的麻烦要比益处多得多。比如,Java只支持有符号整数,并且要求以补码运算来实现。
            正常的右移运算符>>被定义为执行算术右移。特殊的运算符>>>被指定为执行逻辑右移。
            当我们想要把字仅仅看做是位的集合而没有任何数字意义时,无符号数值是非常有用的。
            例如,往一个字中放人描述各种布尔条件的标记(flag)时,就是这样。
            地址自然地就是无符号的,所以系统程序员发现无符号类型是很有帮助的。
            当实现模运算和多精度运算的数学包时,数字是由字的数组来表示的,无符号值也会非常有用.
        ```
    3. 整数运算
        - 概述
        ```
            许多刚人门的程序员非常惊奇地发现,两个正数相加会得出一个负数,而比较表达式x<y和比较表达式x-y<0会产生不同的结果。
            这些属性是由于计算机运算的有限性造成的。理解计算机运算的细微之处能够帮助程序员编写更可靠的代码.
        ```
        - 关于整数运算的最后思考
        ```
            正如我们看到的,计算机执行的“整数″运算实际上是一种模运算形式。表示数字的有限字长限制了可能的值的取值范围,结果运算可能溢出。
            我们还看到,补码表示提供了一种既能表示负数也能表示正数的灵活方法,同时使用了与执行无符号算术相同的位级实现,
            这些运算包括像加法、减法、乘法,甚至除法,无论运算数是以无符号形式还是以补码形式表示的,都有完全一样或者非常类似的位级行为。
        ```
    ###### 小结
    ```
        计算机将信息编码为位(比特),通常组织成字节序列。有不同的编码方式用来表示整数、实数和字符串。
        不同的计算机模型在编码数字和多字节数据中的字节顺序时使用不同的约定.
        C语言的设计可以包容多种不同字长和数字编码的实现0 64位字长的机器逐渐普及,并正在取代统治市场长达30多年的32位机器。
        由于64位机器也可以运行为32位机器编译的程序,我们的重点就放在区分32位和64位程序,而不是机器本身. 
        64位程序的优势是可以突破32位程序具有的4GB地址限制。

        由于编码的长度有限,与传统整数和实数运算相比,计算机运算具有非常不同的属性。
        当超出表示范围时,有限长度能够引起数值溢出。当浮点数非常接近于0.0,从而转换成零时,也会下溢。

        必须非常小心地使用浮点运算,因为浮点运算只有有限的范围和精度,而且并不遵守普遍的算术属性,比如结合性。
    ```
---
* 第三章 程序的机器级表示
    1. 总述
    ```
        计算机执行机器代码,用字节序列编码低级的操作,包括处理数据、管理内存、读写存储设备上的数据,以及利用网络通信。
        编译器基于编程语言的规则、目标机器的指令集和操作系统遵循的惯例,经过一系列的阶段生成机器代码.
        GCC C语言编译器以汇编代码的形式产生输出,汇编代码是机器代码的文本表示,给出程序中的每一条指令。
        然后GCC调用汇编器和链接器,根据汇编代码生成可执行的机器代码。
        在本章中,我们会近距离地观察机器代码,以及人类可读的表示一汇编代码。
        tips: Golang 自带的编译器GC(golang compiler) 与GCC 提供的GCCGO 存在一些不同,选择编译器时应该根据项目定义及需求来考虑
    ```
    2. 程序编码
        - 机器级代码
        ```
        x86-64的机器代码和原始的C代码差别非常大。一些通常对C语言程序员隐藏的处理器状态都是可见的:
            ●程序计数器(通常称为“PC”,在x86-64中用%rip表示)给出将要执行的下一条指令在内存中的地址。
            ●整数寄存器文件包含16个命名的位置,分别存储64位的值。这些寄存器可以存储地址(对应于C语言的指针)或整数数据。
            有的寄存器被用来记录某些重要的程序状态,而其他的寄存器用来保存临时数据,例如过程的参数和局部变量,以及函数的返回值。
            ●条件码寄存器保存着最近执行的算术或逻辑指令的状态信息。它们用来实现控制或数据流中的条件变化,比如说用来实现if和while语旬。
            ●一组向量寄存器可以存放一个或多个整数或浮点数值。

            虽然C语言提供了一种模型,可以在内存中声明和分配备种数据类型的对象,但是机器代码只是简单地将内存看成一个很大的、按字节寻址的数组. 
            C语言中的聚合数据类型,例如数组和结构,在机器代码中用一组连续的字节来表示。
            即使是对标量数据类型,汇编代码也不区分有符号或无符号整数,不区分备种类型的指针,甚至于不区分指针和整数。
            程序内存包含:程序的可执行机器代码,操作系统需要的一些信息,用来管理过程调用和返回的运行时栈,以及用户分配的内存块(比如说用malloc库函数分配的)。
            正如前面提到的,程序内存用虚拟地址来寻址。在任意给定的时刻,只有有限的一部分虚拟地址被认为是合法的。
            例如,x86-64的虚拟地址是由64位的字来表示的。在目前的实现中,这些地址的高16位必须设置为0,所以一个地址实际上能够指定的是248或64TB范围内的一个字节。
            较为典型的程序只会访间几兆字节或几千兆字节的数据。操作系统负责管理虚拟地址空间,将虚拟地址翻译成实际处理器内存中的物理地址。
            一条机器指令只执行一个非常基本的操作。例如,将存放在寄存器中的两个数字相加,在存储器和寄存器之间传送数据,或是条件分支转移到新的指令地址。
            编译器必须产生这些指令的序列,从而实现(像算术表达式求值、循环或过程调用和返回这样的)程序结构。
        ```
        - 访问信息
        ```
            一个x86-64的中央处理单元(CPU)包含一组16个存储64位值的通用目的寄存器。这些寄存器用来存储整数数据和指针。
            
            指令可以对这16个寄存器的低位字节中存放的不同大小的数据进行操作。
            字节级操作可以访问最低的字节,16位操作可以访问最低的2个字节,32位操作可以访问最低的4个字节,而64位操作可以访问整个寄存器。

            tips: 大多数高级语言的数据类型自动扩所容都是基于底层的存储空间访问规则来的. 比如golang 的切片扩容等
            
            在常见的程序里不同的寄存器扮演不同的角色。其中最特别的是栈指针持sp,用来指明运行时栈的结束位置。
            有些程序会明确地读写这个寄存器。另外15个寄存器的用法更灵活。少量指令会使用某些特定的寄存器。
            更重要的是,有一组标准的编程规范控制着如何使用寄存器来管理栈、传递函数参数、从函数的返回值,以及存储局部和临时数据。
            我们会在描述过程的实现时(特别是在3.7节中),讲述这些惯例.
        ```
        - 数据传送指令
        ```
            最频繁使用的指令是将数据从一个位置复制到另一个位置的指令。
            操作数表示的通用性使得一条简单的数据传送指令能够完成在许多机器中要好几条不同指令才能完成的功能。
            我们会介绍多种不同的数据传送指令,它们或者源和目的类型不同,或者执行的转换不同,或者具有的一些副作用不同.

            源操作数指定的值是一个立即数,存储在寄存器中或者内存中。目的操作数指定一个位置,要么是一个寄存器或者,要么是一个内存地址. 
            x86-64加了一条限制,传送指令的两个操作数不能都指向内存位置。将一个值从一个内存位置复制到另一个内存位置需要两条指令:
            第一条指令将源值加载到寄存器中,
            第二条将该寄存器值写人目的位置。
        ```
        - 过程
        ```
            过程是软件中一种很重要的抽象。它提供了一种封装代码的方式,用一组指定的参数和一个可选的返回值实现了某种功能。
            然后,可以在程序中不同的地方调用这个函数。设计良好的软件用过程作为抽象机制,隐藏某个行为的具体实现,
            同时又提供清晰简洁的接日定义,说明要计算的是哪些值,过程会对程序状态产生什么样的影响。
            不同编程语言中,过程的形式多样:函数(function),方法(method),子例程(subroutine),处理函数(handler)等等,但是它们有一些共有的特性。

            要提供对过程的机器级支持,必须要处理许多不同的属性。为了讨论方便,假设过程P调用过程Q,Q执行后返回到P.
            这些动作包括下面一个或多个机制:
            传递控制。在进人过程Q的时候,程序计数器必须被设置为Q的代码的起始地址,然后在返回时,要把程序计数器设置为p中调用Q后面那条指令的地址。
            传递数据. p必须能够向Q提供一个或多个参数,Q必须能够向p返回一个值。
            分配和释放内存。在开始时,Q可能需要为局部变量分配空间,而在返回前,又必须释放这些存储空间o
        ```
        - 运行时栈
        ```
            C语言过程调用机制的一个关键特性(大多数其他语言也是如此)在于使用了栈数据结构提供的后进先出的内存管理原则。
            在过程P调用过程Q的例子中,可以看到当Q在执行时,P以及所有在向上追溯到p的调用链中的过程,都是暂时被挂起的。
            当Q运行时,它只需要为局部变量分配新的存储空间,或者设置到另一个过程的调用。
            另一方面,当Q返回时,任何它所分配的局部存储空间都可以被释放。
            因此,程序可以用栈来管理它的过程所需要的存储空间,栈和程序寄存器存放着传递控制和数据、分配内存所需要的信息。
            当P调用Q时,控制和数据信息添加到栈尾。当p返回时,这些信息会释放掉。

            为了提高空间和时间效率,x86-64过程只分配自已所需要的栈帧部分。例如,许多过程有6个或者更少的参数,那么所有的参数都可以通过寄存器传递。
            因此,图3-25中画出的某些栈帧部分可以省略。实际上,许多函数甚至根本不需要栈帧。
            当所有的局部变量都可以保存在寄存器中,而且该函数不会调用任何其他函数(有时称之为叶子过程,此时把过程调用看做树结构)时,就可以这样处理。
            例如,到目前为止我们仔细审视过的所有函数都不需要栈帧.
        ```
        - 数据传送
        ```
            当调用一个过程时,除了要把控制传递给它并在过程返回时再传递回来之外,过程调用还可能包括把数据作为参数传递,而从过程返回还有可能包括返回一个值. 
            x86-64中,大部分过程间的数据传送是通过寄存器实现的。例如,我们已经看到无数的函数示例,参数在寄存器%rdi、%rsi和其他寄存器中传递。
            当过程P调用过程Q时,P的代码必须首先把参数复制到适当的寄存器中。类似地,当Q返回到p时,P的代码可以访问寄存器%rax中的返回值。
        ```
        - 栈上的局部存储
        ```
            到目前为止我们看到的大多数过程示例都不需要超出寄存器大小的本地存储区域。
            不过有些时候,局部数据必须存放在内存中,常见的情况包括:
            1. 寄存器不足够存放所有的本地数据。
            2. 对一个局部变量使用地址运算符‘&’,因此必须能够为它产生一个地址。
            3. 某些局部变量是数组或结构,因此必须能够通过数组或结构引用被访问到。在描述数组和结构分配时,我们会讨论这个间题。
        ```
        - 寄存器中的局部存储空间
        ```
            寄存器组是唯一被所有过程共享的资源。
            虽然在给定时刻只有一个过程是活动的,我们仍然必须确保当一个过程(调用者)调用另一个过程(被调用者)时,
            被调用者不会覆盖调用者稍后会使用的寄存器值。为此,x86-64采用了一组统一的寄存器使用惯例,所有的过程(包括程序库)都必须遵循。

            根据惯例,寄存器%rbx、frbp和%r12-fr15被划分为被调用者保存寄存器。
            当过程P调用过程Q时,Q必须保存这些寄存器的值,保证它们的值在Q返回到p时与Q被调用时是一样的。
            过程Q保存一个寄存器的值不变,要么就是根本不去改变它,要么就是把原始值压人栈中,改变寄存器的值,然后在返回前从栈中弹出旧值。
            压人寄存器的值会在栈帧中创建标号为“保存的寄存器”的一部分,如图3-25中所示。
            有了这条惯例,P的代码就能安全地把值存在被调用者保存寄存器中(当然,要先把之前的值保存到栈上),调用Q,然后继续使用寄存器中的值,不用担心值被破坏。
        ```
        - 递归过程
        ```
            前面已经描述的寄存器和栈的惯例使得x86-64过程能够递归地调用它们自身。
            每个过程调用在栈中都有它自已的私有空间,因此多个未完成调用的局部变量不会相互影响。
            此外,栈的原则很自然地就提供了适当的策略,当过程被调用时分配局部存储,当返回时释放存储。
        ```
    ###### 小结
    ```
        在本章中， 我们窥视了c语言提供的抽象层下面的东西，以了解机器级编程。 
        通过让编译器产生机 器级程序的汇编代码表 示， 我们了解了编译器和它的优化能力， 
        以及机器、数据类型和指令集。在第 5 章， 我们会看到， 当编写能有效映射到机器上的 程序时， 了解编译器的特性会有所帮助。
        我们还更完整 地了解了程序如何将数据存储在不同的内存区域中。在第 12 章会看到许多 这样的例子，
        应用程序员需要 知道一个程序变量是在运行时栈中，是在某个动态分配的数据结构中，还是全局程序数据的一部分。
        理解程序如何映射到机器上，会让理解这些存储类型之间的区别容易一些。
    ```
---

* 第四章 处理器体系结构
    1. 综述
    ```
        现代微处理器可以称得上是人类创造出的最复杂的系统之一。一块手指甲大小的硅片上， 可以容纳一个完整的高性能处理器、大的高速缓存， 
        以及用来连接到外部设备的逻辑电路。 从性能上来 说， 今天在一块芯片上实现的处理器已经使20年前价值1000万美元、房间那么大的超级计算机相形见绌了。 
        即使是在像手机、导航系统和可编程恒温器这样的日常设备中的嵌入式处理器，也比早期计算机开发者所能想到的强大得多。

        到目前为止，我们看到的计算机系统只限于机器语言程序级。我们知道处理器必须执行一系列指令，每条指令执行某个简单操作， 
        例如两个数相加。指令被编码为由一个或多个字节序列组成的二进制格式。 
        一个处理器支持的指令和指令的字节级编码称为它的指令集体系结构（Instruction-Set Architecture,ISA）

        因此， ISA在编译器编写者和处理器设计人员之间提供了一个概念抽象层，编译器编写者只需要知道允许哪些指令， 
        以及它们是如何编码的；而处理器设计者必须建造出执行这些指令的处理器。
    ```
    2. 列举数据冒险的类型
    ```
        当一条指令更新后面指令会读到的那些程序状态时，就有可能出现冒险。对于 Y86-64 来说，程序状态包括程序寄存器、程序计数器、内存、条件码寄存器和状态寄存器。 
        让我们来看看在提出的设计中每类状态出现冒险的可能性。

        程序寄存器： 我们已经认识这种冒险了。出现这种冒险是因为寄存器文件的读写是在不同的阶段进行的,导致不同指令之间可能出现不希望的相互作用。
        程序计数器： 更新和读取程序计数器之间的冲突导致了控制冒险。当我们的取指阶段逻辑在取下一条指令之前， 
        正确预测了程序计数器的新值时，就不会产生冒险。预测错误的分支和ret指令需要特殊的处理
        内存： 对数据内存的读和写都发生在访存阶段。在一条读内存的指令到达这个阶段之前，前面所有要写内存的指令都已经完成这个阶段了。 
        另外，在访存阶段中写数据的指令和在取指阶段中读指令之间也有冲突，因为指令和数据内存访问的是同一个地址空间。
        条件码寄存器： 在执行阶段中，整数操作会写这些寄存器。条件传送指令会在执行阶段以及条件转移会在访存阶段读这些寄存器。 
        在条件传送或转移到达执行阶段之前，前面所有的整数操作都已经完成这个阶段了。所以不会发生冒险。
        状态寄存器： 指令流经流水线的时候，会影响程序状态。我们采用流水线中的每条指令都与一个状态码相关联的机制，使得当异常发生时，处理器能够有条理地停止.
    ```
    ###### 小结
    ```
        我们已经看到，指令集体系结构，即ISA, 在处理器行为（就指令集合及其编码而言）和如何实现处理器之间提供了一层抽象。 
        ISA提供了程序执行的一种顺序说明，也就是一条指令执行完了，下一条指 令才会开始。

        从IA32指令开始，大大简化数据类型、地址模式和指令编码，我们定义了Y86-64指令集。
        得到的ISA既有RISC指令集的属性，也有CISC指令集的属性。然后，将不同指令组织放到五个阶段中处理, 
        在此，根据被执行的指令的不同，每个阶段中的操作也不相同。据此，我们构造了SEQ处理器，其中每个时钟周期执行一条指令，它会通过所有五个阶段。

        流水线化通过让不同的阶段并行操作，改进了系统的吞吐量性能。在任意一个给定的时刻,多条指令被不同的阶段处理。
        在引入这种并行性的过程中，我们必须非常小心，以提供与程序的顺序执行相同的程序级行为。 
        通过重新调整SEQ各个部分的顺序，引入流水线，我们得到SEQ+,接着添加流水线寄存器， 
        创建岀PIPE一流水线。然后，添加了转发逻辑，加速了将结果从一条指令发送到另一条指令， 
        从而提高了流水线的性能。有几种特殊情况需要额外的流水线控制逻辑来暂停或取消一些流水线阶段。

        我们的设计中包括了一些基本的异常处理机制,在此,保证只有到异常指令之前的指令会影响程序员可见的状态。
        实现完整的异常处理远比此更具挑战性。在采用了更深流水线和更多并行性的系统中，要想正确处理异常就更加复杂了。

        在本章中，我们学习了有关处理器设计的几个重要经验：
            1.  管理复杂性是首要问题。想要优化使用硬件资源，在最小的成本下获得最大的性能。为了实现这个目的， 
            我们创建了一个非常简单而一致的框架，来处理所有不同的指令类型。有了这个框架，就能够在处理不同指令类型的逻辑中共享硬件单元。
            2. 我们不需要直接实现ISA.ISA的直接实现意味着一个顺序的设计。为了获得更高的性能,我们想运用硬件能力以同时执行许多操作， 
            这就导致要使用流水线化的设计。通过仔细的设计和分析，我们能够处理各种流水线冒险，因此运行一个程序的整体效果， 
            同用ISA模型获得的效果完全一致。
            3. 硬件设计人员必须非常谨慎小心。一旦芯片被制造出来，就几乎不可能改正任何错误了。一开始就使设计正确是非常重要的。 
            这就意味着要仔细地分析各种指令类型和组合，甚至于那些看上去没有意义的情况，例如弹出值到栈指针。
            必须用系统的模拟测试程序彻底地测试设计。在开发PIPE的控制逻辑中，我们的设计有个细微的错误， 
            只有通过对控制组合的 仔细而系统的分析才能发现。
    ```
---

* 第五章 优化程序性能
    1. 综述
    ```
        写程序最主要的目标就是使它在所有可能的情况下都正确工作。
        一个运行得很快但是给岀错误结果的程序没有任何用处。
        程序员必须写出清晰简洁的代码,这样做不仅是为了自己能够看懂代码，
        也是为了在检查代码和今后需要修改代码时，其他人能够读懂和理解代码。

        另一方面，在很多情况下，让程序运行得快也是一个重要的考虑因素。如果一个程序要实时地处理视频帧或者网络包，
        一个运行得很慢的程序就不能提供所需的功能。当一个计算任务的计算量非常大，需要执行数日或者数周， 
        那么哪怕只是让它运行得快20%也会产生重大的影响。本章会探讨如何使用几种不同类型的程序优化技术，使程序运行得更快。

        编写高效程序需要做到以下几点：第一，我们必须选择一组适当的算法和数据结构。第二，我们必须编写岀编译器能够有效优化以转换成高效可执行代码的源代码。
        对于这第二点，理解优化编译器的能力和局限性是很重要的。编写程序方式中看上去只是一点小小的变动， 
        都会引起编译器优化方式很大的变化。有些编程语言比其他语言容易优化。C语言的有些特性，例如执行指针运算和强制类型转换的能力，
        使得编译器很难对它进行优化。程序员经常能够以一种使编译器更容易产生高效代码的方式来编写他们的程序。
        第三项技术针对处理运算量特别大的计算，将一个任务分成多个部分,这些部分可以在多核和多处理器的某种组合上并行地计算。
        我们会把这种性能改进的方法推迟到第12章中去讲。即使是要利用并行性，每个并行的线程都以最高性能执行也是非常重要的， 
        所以无论如何本章所讲的内容也还是有意义的。

        在程序开发和优化的过程中，我们必须考虑代码使用的方式，以及影响它的关键因素。
        通常，程序员必须在实现和维护程序的简单性与它的运行速度之间做出权衡。在算法级上，几分钟就能编写一个简单的插入排序，
        而一个高效的排序算法程序可能需要一天或更长的时间来实现和优化。在代码级上，
        许多低级别的优化往往会降低程序的可读性和模块性，使得程序容易出错，并且更难以修改或扩展。 
        对于在性能重要的环境中反复执行的代码，进行大量的优化会比较合适。一个挑战就是尽管做了大量的变化，
        但还是要维护代 码一定程度的简洁和可读性。

        我们描述许多提高代码性能的技术。理想的情况是，编译器能够接受我们编写的任何代码， 
        并产生尽可能高效的、具有指定行为的机器级程序。现代编译器釆用了复杂的分析和优化形式， 
        而且变得越来越好。然而，即使是最好的编译器也受到妨碍优化的因素(optimization blocker)的阻碍，
        妨碍优化的因素就是程序行为中那些严重依赖于执行环境的方面。程序员必须编写容易优化的代码，以帮助编译器。

        程序优化的第一步就是消除不必要的工作，让代码尽可能有效地执行所期望的任务。
        这包括消除不必要的函数调用、条件测试和内存引用。这些优化不依赖于目标机器的任何具体属性。

        为了使程序性能最大化，程序员和编译器都需要一个目标机器的模型，指明如何处理指令，以及各个操作的时序特性。
        例如，编译器必须知道时序信息，才能够确定是用一条乘法指令，还是用移位和加法的某种组合。
        现代计算机用复杂的技术来处理机器级程序，并行地执行许多指令，执行顺序还可能不同于它们在程序中出现的顺序。
        程序员必须理解这些处理器是如何工作的，从而调整他们的程序以获得最大的速度.基于Intel和AMD处理器最近的设计， 
        我们提出了这种机器的一个高级模型。我们还设计了一种图形数据流(data-flow)表示法， 
        可以使处理器对指令的执行形象化，我们还可以利用它预测程序的性能。

        对于新手程序员来说，不断修改源代码，试图欺骗编译器产生有效的代码，看起来很奇怪，但这确实是编写很多高性能程序的方式。
        比较于另一种方法一一用汇编语言写代码，这种间接的方法具有的优点是：虽然性能不一定是最好的，但得到的代码仍然能够在其他机器上运行。
    ```
    2. 优化编译器 的能力和局限性
        - 综述
        ```
            现代编译器运用复杂精细的算法来确定一个程序中计算的是什么值，以及它们是被如何使用的。 
            然后会利用一些机会来简化表达式，在几个不同的地方使用同一个计算，以及降低一个给定的计算必须被执行的次数。 
            大多数编译器，包括 GCC,向用户提供了一些对它们所使用的优化的控制。就像在第3章中讨论过的，最简单的控制就是指定优化级别。

            编译器并不清楚程序的意图以及一些过程(函数)何时会被调用.这一系列原因使得编译器只能保守的进行优化,也就是编译器优化程序性能有一定的局限性.
        ```
    3. 理解现代处理器
        - 综述
        ```
            为了理解改进性能的方法，我们需要理解现代处理器的微体系结构。由于大量的晶体管可以被集成到一块芯片上， 
            现代微处理器采用了复杂的硬件，试图使程序性能最大化。带来的一个后果就是处理器的实际操作与通过观察机器级程序所察觉到的大相径庭。 
            在代码级上，看上去似乎是一次执行一条指令，每条指令都包括从寄存器或内存取值，执行一个操作，并把结果存回到一个寄存器或内存位置。 
            在实际的处理器中，是同时对多条指令求值的，这个现象称为 [指令级并行]。在某些设计中，可以有100或更多条指令在处理中。
            釆用一些精细的机制来确保这种并行执行的行为，正好能获得机器级程序要求的顺序语义模型的效果。 
            现代微处理器取得的了不起的功绩之一是：它们采用复杂而奇异的微处理器结构，其中，多条指令可以并行地执行，同时又呈现出一种简单的顺序执行指令的表象。

            虽然现代微处理器的详细设计超出了本书讲授的范围,对这些微处理器运行的原则有一般性的了解就足够能够理解它们如何实现指令级并行。 
            我们会发现两种下界描述了程序的最大性能。当一系列操作必须按照严格顺序执行时，就会遇到延迟界限(latency bound),
            因为在下一条指令开始之前，这条指令必须结束。当代码中的数据相关限制了处理器利用指令级并行的能力时，延迟界限能够限制程序性能。
            吞吐量界限(throughput bound)刻画了处理器功能单元的原始计算能力。这个界限是程序性能的终极限制。
        ```
        - 整体操作
        ```
            我们假想的处理器设计是不太严格地基于近期的Intel处理器的结构.这些处理器在工业界称为超标量(superscalar),
            意思是它可以在每个时钟周期执行多个操作，而且是乱序的(out-of-order),意思就是指令执行的顺序不一定要与它们在机器级程序中的顺序一致。 
            整个设计有两个主要部分：指令控制单元(Instruction Control Unit, ICU)和执行单元(Execution Unit, EU).
            前者负责从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作；而后者执行这些操作。
            和第4章中研究过的按序(in-order)流水线相比，乱序处理器需要更大、更复杂的硬件，但是它们能更好地达到更高的指令级并行度。
            即试图以空间换时间

            指令译码逻辑接收实际的程序指令，并将它们转换成一组基本操作(有时称为微操作)。每个这样的操作都完成某个简单的计算任务， 
            例如两个数相加，从内存中读数据，或是向内存写数据。对于具有复杂指令的机器,比如 x86 处理器 , 
            一条指令可以被译码成多个操作。关于指令如何被译码成操作序列的细节，不同的机器都会不同，这个信息可谓是高度机密。
            幸运的是，不需要知道某台机器实现的底层细节，我们也能优化自己的程序。

            addq %rax,%rdx会被转化成一个操作。另一方面，一条包括一个或者多个内存引用的指令，例如addq %rax,8(%rdx)会产生多个操作， 
            把内存引用和算术运算分开。这条指令会被译码成为三个操作：一个操作从内存中加载一个值到处理器中,
            一个操作将加载进来的值加上寄存器％ 0X 中的值，而一个操作将结果存 回到内存。这种译码逻辑对指令进行分解， 
            允许任务在一组专门的硬件单元之间进行分割。这些单元可以并行地执行多条指令的不同部分。

            总的来说，重新结合变换能够减少计算中关键路径上操作的数量，通过更好地利用功能单元的流水线能力得到更好的性能。 
            大多数编译器不会尝试对浮点运算做重新结合，因为这些运算不保证是可结合的。当前的GCC版本会对整数运算执行重新结合， 
            但不是总有好的效果。通常，我们发现循环展开和并行地累积在多个值中，是提高程序性能的更可靠的方法。
        ```
        - 优化合并代码的结果小结
        ```
            使用多项优化技术，我们获得的CPE已经接近于0. 50和1.00的吞吐量界限，只受限于功能单元的容量。
            与原始代码相比提升了10〜20倍，且使用普通的C代码和标准编译器就获得了所有这些改进。
            重写代码利用较新的SIMD指令得到了将近4倍或8倍的性能提升。比如单精度乘法，CPE从初值11.14降到了0.06,整体性能提升超过180倍。
            这个例子说明现代处理器具有相当的计算能力，但是我们可能需要按非常程式化的方式来编写程序以便将这些能力诱发出来。
        ```
        - 一些限制因素
        ```
            循环并行性的好处受汇编代码描述计算的能力限制。如果我们的并行度力超过了可用的寄存器数量，
            那么编译器会诉诸溢出(spilling),将某些临时值存放到内存中，通常是在运行时堆栈上分配空间。

            一旦编译器必须要诉诸寄存器溢出，那么维护多个累积变量的优势就很可能消失。
            幸运的是，x86-64有足够多的寄存器，大多数循环在出现寄存器溢岀之前就将达到吞吐量限制。
        ```
        - 分支预测和预测错误处罚
        ```
            在一个使用投机执行(speculative execution)的处理器中，处理器会开始执行预测的分支目标处的指令。
            它会避免修改任何实际的寄存器或内存位置，直到确定了实际的结果。如果预测正确，那么处理器就会“提交”投机执行的指令的结果，把它们存储到寄存器或内存。
            如果预测错误，处理器必须丢弃掉所有投机执行的结果，在正确的位置，重新开始取指令的过程。
            这样做会引起预测错误处罚，因为在产生有用的结果之前，必须重新填充指令流水线。
        ```
        - 理解内存性能
        ```
            到目前为止我们写的所有代码，以及运行的所有测试，只访问相对比较少量的内存。
            例如，我们都是在长度小于1000个元素的向量上测试这些合并函数，数据量不会超过8000个字节。
            所有的现代处理器都包含一个或多个高速缓存（cache）存储器，以对这样少量的存储器提供快速的访问。
            本节会进一步研究涉及加载（从内存读到寄存器）和存储（从寄存器写到内存）操作的程序的性能，只考虑所有的数据都存放在高速缓存中的情况。
            在第6章，我们会更详细地探究高速缓存是如何工作的，它们的性能特性，以及如何编写充分利用高速缓存的代码。

            现代处理器有专门的功能单元来执行加载和存储操作，这些单元有内部的缓冲区来保存未完成的内存操作请求集合。

            1. 加载的性能
            一个包含加载操作的程序的性能既依赖于流水线的能力，也依赖于加载单元的延迟。
            2. 存储的性能
            在迄今为止所有的示例中，我们只分析了大部分内存引用都是加载操作的函数，也就是从内存位置读到寄存器中。
            与之对应的是存储(store)操作，它将一个寄存器值写到内存。这个操作的性能，尤其是与加载操作的相互关系，包括一些很细微的问题。
            与到目前为止我们已经考虑过的其他操作不同，存储操作并不影响任何寄存器值。因此，就其本性来说，一系列存储操作不会产生数据相关。
            只有加载操作会受存储操作结果的影响，因为只有加载操作能从由存储操作写的那个位置读回值。
            2. 应用：性能提高技术
                虽然只考虑了有限的一组应用程序，但是我们能得出关于如何编写高效代码的很重要的经验教训。我们已经描述了许多优化程序性能的基本策略：
                1）高级设计。为遇到的问题选择适当的算法和数据结构。要特别警觉，避免使用那些会渐进地产生糟糕性能的算法或编码技术。
                2）基本编码原则。避免限制优化的因素，这样编译器就能产生高效的代码。
                    •消除连续的函数调用。在可能时，将计算移到循环外。考虑有选择地妥协程序的模块性以获得更大的效率。
                    •消除不必要的内存引用。引入临时变量来保存中间结果。只有在最后的值计算出来时，才将结果存放到数组或全局变量中。
                3)低级优化。结构化代码以利用硬件功能。
                    •展开循环，降低开销，并且使得进一步的优化成为可能。
                    •通过使用例如多个累积变量和重新结合等技术，找到方法提高指令级并行。
                    •用功能性的风格重写条件操作，使得编译采用条件数据传送。
            最后要给读者一个忠告，要警惕，在为了提高效率重写程序时避免引入错误。在引入新变量、改变循环边界和使得代码整体上更复杂时，很容易犯错误。
            一项有用的技术是在优化函数时，用检查代码来测试函数的每个版本，以确保在这个过程没有引入错误。检查代码对函数的新版本实施一系列的测试，
            确保它们产生与原来一样的结果。对于高度优化的代码，这组测试情况必须变得更加广泛，因为要考虑的情况也更多。
            例如，使用循环展开的检查代码需要测试许多不同的循环界限，保证它能够处理最终单步迭代所需要的所有不同的可能的数字。

        ```
    ###### 小结
    ```
        虽然关于代码优化的大多数论述都描述了编译器是如何能生成高效代码的，但是应用程序员有很多方法来协助编译器完成这项任务。
        没有任何编译器能用一个好的算法或数据结构代替低效率的算法或数据结构，因此程序设计的这些方面仍然应该是程序员主要关心的。
        我们还看到妨碍优化的因素，例如内存别名使用和过程调用，严重限制了编译器执行大量优化的能力。
        同样，程序员必须对消除这些妨碍优化的因素负主要的责任。这些应该被看作好的编程习惯的一部分，因为它们可以用来消除不必要的工作。

        基本级别之外调整性能需要一些对处理器微体系结构的理解，描述处理器用来实现它的指令集体系结构的底层机制。
        对于乱序处理器的情况，只需要知道一些关于操作、容量、延迟和功能单元发射时间的信息，就能够基本地预测程序的性能了。

        我们研究了一系列技术，包括循环展开、创建多个累积变量和重新结合，它们可以利用现代处理器提供的指令级并行。
        随着对优化的深入，研究产生的汇编代码以及试着理解机器如何执行计算变得重要起来。
        确认由程序中的数据相关决定的关键路径，尤其是循环的不同迭代之间的数据相关，会收获良多。
        我们还可以根据必须要计算的操作数量以及执行这些操作的功能单元的数量和发射时间，计算一个计算的吞吐量界限。

        包含条件分支或与内存系统复杂交互的程序，比我们最开始考虑的简单循环程序，更难以分析和优化。
        基本策略是使分支更容易预测，或者使它们很容易用条件数据传送来实现。我们还必须注意存储和加载操作。
        将数值保存在局部变量中，使得它们可以存放在寄存器中，这会很有帮助。

        当处理大型程序时，将注意力集中在最耗时的部分变得很重要。代码剖析程序和相关的工具能帮助我们系统地评价和改进程序性能。
        我们描述了GPROF,一个标准的Unix剖析工具。
    ```

--- 

* 第六章 存储器层次结构
    -  概述
    ```
        到目前为止，在对系统的研究中，我们依赖于一个简单的计算机系统模型，CPU执行指令，而存储器系统为CPU存放指令和数据。
        在简单模型中，存储器系统是一个线性的字节数组，而CPU能够在一个常数时间内访问每个存储器位置。
        虽然迄今为止这都是一个有效的模型，但是它没有反映现代系统实际工作的方式。

        实际上，存储器系统(memory system)是一个具有不同容量、成本和访问时间的存储设备的层次结构。
        CPU寄存器保存着最常用的数据。靠近CPU的小的、快速的高速缓存存储器(cache memory)作为一部分存储在相对慢速的主存储器(main memory)中数据和指令的缓冲区域。
        主存缓存存储在容量较大的、慢速磁盘上的数据，而这些磁盘常常又作为存储在通过网络连接的其他机器的磁盘或磁带上的数据的缓冲区域。

        存储器层次结构是可行的，这是因为与下一个更低层次的存储设备相比来说，一个编写良好的程序倾向于更频繁地访问某一个层次上的存储设备。
        所以，下一层的存储设备可以更慢速一点，也因此可以更大，每个比特位更便宜。
        整体效果是一个大的存储器池，其成本与层次结构底层最便宜的存储设备相当，但是却以接近于层次结构顶部存储设备的高速率向程序提供数据。

        作为一个程序员，你需要理解存储器层次结构，因为它对应用程序的性能有着巨大的影响。
        如果你的程序需要的数据是存储在CPU寄存器中的，那么在指令的执行期间，在0个周期内就能访问到它们。
        如果存储在高速缓存中，需要4〜75个周期。如果存储在主存中，需要上百个周期。而如果存储在磁盘上，需要大约几千万个周期！

        这里就是计算机系统中一个基本而持久的思想：如果你理解了系统是如何将数据在存储器层次结构中上上下下移动的，
        那么你就可以编写自己的应用程序，使得它们的数据项存储在层次结构中较高的地方，在那里CPU能更快地访问到它们。
    ```
    1. 存储技术
        -   概述
        ```
            计算机技术的成功很大程度上源自于存储技术的巨大进步。早期的计算机只有几千字节的随机访问存储器。
            最早的IBM PC甚至于没有硬盘。1982年引入的IBM PC-XT有10M字节的磁盘。到2015年，典型的计算机已有300 000倍于PC-XT的磁盘存储，
            而且磁盘的容量以每两年加倍的速度增长。

        ```
        - 随机访问存储器
        ```
            随机访问存储器(Random-Access Memory,RAM)分为两类：静态的和动态的。静态RAM(SRAM)比动态RAM (DRAM)更快，但也贵得多。
            SRAM用来作为高速缓存存储器,既可以在CPU芯片上，也可以在片下。
            DRAM用来作为主存以及图形系统的帧缓冲区。典型地，一个桌面系统的SRAM不会超过几兆字节，但是DRAM却有几百或几千兆字节。
            只要有供电，SRAM就会保持不变。与DRAM不同，它不需要刷新。SRAM的存取比DRAM快。SRAM对诸如光和电噪声这样的干扰不敏感。
            代价是SRAM单元比DRAM单元使用更多的晶体管，因而密集度低，而且更贵，功耗更大。
        ```
        - 访问主存
        ```
            数据流通过称为总线(bus)的共享电子电路在处理器和DRAM主存之间来来回回。每次CPU和主存之间的数据传送都是通过一系列步骤来完成的，
            这些步骤称为总线事务(bus transaction).读事务(read transaction)从主存传送数据到CPU.写事务(write transaction)从CPU传送数据到主存。
        ```
        - 磁盘存储
        ```
            磁盘是广为应用的保存大量数据的存储设备，存储数据的数量级可以达到几百到几千千兆字节，而基于RAM的存储器只能有几百或几千兆字节。
            不过，从磁盘上读信息的时间为毫秒级，比从DRAM读慢了10万倍，比从SRAM读慢了100万倍。
            1. 磁盘构造
            磁盘是由盘片(platter)构成的。每个盘片有两面或者称为表面(surface),表面覆盖着磁性记录材料。
            盘片中央有一个可以旋转的主轴(spindle),它使得盘片以固定的旋转速率(rotational rate)旋转，
            通常是5400〜15 000转每分钟(Revolution Per Minute, RPM)。磁盘通常包含一个或多个这样的盘片，并封装在一个密封的容器内。
            2. 磁盘容量
            一个磁盘上可以记录的最大位数称为它的最大容量，以下技术因素决定的：
                记录密度
                磁道密度
                面密度
                磁盘制造商不懈地努力以提高面密度(从而增加容量)，而面密度每隔几年就会翻倍。
            3. 磁盘操作
            磁盘用读/写头(read/writehead)来读写存储在磁性表面的位，而读写头连接到一个传动臂(actuator arm)一端
                寻道时间：为了读取某个目标扇区的内容，传动臂首先将读/写头定位到包含目标扇区的磁道上。
                旋转时间：一旦读/写头定位到了期望的磁道，驱动器等待目标扇区的第一个位旋转到读/写头下。
                传送时间：当目标扇区的第一个位位于读/写头下时，驱动器就可以开始读或者写该扇区的内容了。一个扇区的传送时间依赖于旋转速度和每条磁道的扇区数目。
            对存储在SRAM中的一个64位字的访问时间大约是4ns,对DRAM的访问时间是60ns。
            因此，从内存中读一个512个字节扇区大小的块的时间对SRAM来说大约是256ns,对DRAM来说大约是4000ns。
            磁盘访问时间，大约10ms,是SRAM的大约40 000倍，是DRAM的大约2500倍。
            4. 逻辑磁盘块
            当操作系统想要执行一个I/O操作时，例如读一个磁盘扇区的数据到主存，操作系统会发送一个命令到磁盘控制器，
            让它读某个逻辑块号。控制器上的固件执行一个快速表查找，将一个逻辑块号翻译成一个（盘面，磁道，扇区）的三元组，
            这个三元组唯一地标识了对应的物理扇区。控制器上的硬件会解释这个三元组，将读/写头移动到适当的柱面，
            等待扇区移动到读/写头下，将读/写头感知到的位放到控制器上的一个小缓冲区中，然后将它们复制到主存中。
        ```
        - 固态硬盘
        ```
            固态硬盘(Solid State Disk, SSD)是一种基于闪存的存储技术在某些情况下是传统旋转磁盘的极有吸引力的替代产品。

            比起旋转磁盘，SSD有很多优点。它们由半导体存储器构成，没有移动的部件，因而随机访问时间比旋转磁盘要快，能耗更低，同时也更结实。
            不过，也有一些缺点。首先，因为反复写之后，闪存块会磨损，所以SSD也容易磨损。
            闪存翻译层中的平均磨损（wear leveling）逻辑试图通过将擦除平均分布在所有的块上来最大化每个块的寿命。
            实际上，平均磨损逻辑处理得非常好，要很多年SSD才会磨损坏。其次，SSD每字节比旋转磁盘贵大约30倍，因此常用的存储容量比旋转磁盘小100倍。
            不过，随着SSD变得越来越受欢迎，它的价格下降得非常快，而两者的价格差也在减少。
        ```
        - 存储技术趋势
        ```
            从我们对存储技术的讨论中，可以总结出几个很重要的思想：
            不同的存储技术有不同的价格和性能折中。SRAM比DRAM快一点，而DRAM比磁盘要快很多。
            另一方面，快速存储总是比慢速存储要贵的。SRAM每字节的造价比DRAM高，DRAM的造价又比磁盘高得多。SSD位于DRAM和旋转磁盘之间。
            随着技术不断进步，这些差距在慢慢减少。
        ```
    2. 局部性
        - 概述
        ```
            一个编写良好的计算机程序常常具有良好的局部性(locality).也就是，它们倾向于引用邻近于其他最近引用过的数据项的数据项，
            或者最近引用过的数据项本身。这种倾向性，被称为局部性原理(principle of locality),是一个持久的概念，对硬件和软件系统的设计和性能都有着极大的影响。

            局部性通常有两种不同的形式：时间局部性(temporal locality)和空间局部性(spatial locality).在一个具有良好时间局部性的程序中，
            被引用过一次的内存位置很可能在不远的将来再被多次引用。在一个具有良好空间局部性的程序中，如果一个内存位置被引用了一次，
            那么程序很可能在不远的将来引用附近的一个内存位置。

            程序员应该理解局部性原理，因为一般而言，有良好局部性的程序比局部性差的程序运行得更快。
            现代计算机系统的各个层次，从硬件到操作系统、再到应用程序，它们的设计都利用了局部性。
            在硬件层，局部性原理允许计算机设计者通过引入称为高速缓存存储器的小而快速的存储器来保存最近被引用的指令和数据项，从而提高对主存的访问速度。

        ```
        - 局部性小结
        ```
            在这一节中，我们介绍了局部性的基本思想，还给出了量化评价程序中局部性的一些简单原则：

            •重复引用相同变量的程序有良好的时间局部性。
            •对于具有步长为为的引用模式的程序，步长越小，空间局部性越好。具有步长为Z的引用模式的程序有很好的空间局部性。
            在内存中以大步长跳来跳去的程序空间局部性会很差。
            •对于取指令来说，循环有好的时间和空间局部性。循环体越小，循环迭代次数越多，局部性越好。

            在本章后面，在我们学习了高速缓存存储器以及它们是如何工作的之后，我们会介绍如何用高速缓存命中率和不命中率来量化局部性的概念。
            你还会弄明白为什么有良好局部性的程序通常比局部性差的程序运行得更快。尽管如此，
            了解如何看一眼源代码就能获得对程序中局部性的高层次的认识，是程序员要掌握的一项有用而且重要的技能。
        ```
    3. 存储器层次结构
        - 概述
        ```
            一般而言，从高层往底层走，存储设备变得更慢、更便宜和更大。在最高层（L0）,是少量快速的CPU寄存器，
            CPU可以在一个时钟周期内访问它们。接下来是一个或多个小型到中型的基于SRAM的高速缓存存储器，可以在几个CPU时钟周期内访问它们。
            然后是一个大的基于DRAM的主存，可以在几十到几百个时钟周期内访问它们。接下来是慢速但是容量很大的本地磁盘。
            最后，有些系统甚至包括了一层附加的远程服务器上的磁盘，要通过网络来访问它们。

            概括来说，基于缓存的存储器层次结构行之有效，是因为较慢的存储设备比较快的存储设备更便宜，还因为程序倾向于展示局部性：
            •利用时间局部性：由于时间局部性，同一数据对象可能会被多次使用。一旦一个数据对象在第一次不命中时被复制到缓存中，
            我们就会期望后面对该目标有一系列的访问命中。因为缓存比低一层的存储设备更快，对后面的命中的服务会比最开始的不命中快很多。
            •利用空间局部性：块通常包含有多个数据对象。由于空间局部性，我们会期望后面对该块中其他对象的访问能够补偿不命中后复制该块的花费。
        ```
    4. 高速缓存存储器
        - 概述
        ```
            早期计算机系统的存储器层次结构只有三层：CPU寄存器、DRAM主存储器和磁盘存储。不过，由于CPU和主存之间逐渐增大的差距，
            系统设计者被迫在CPU寄存器文件和主存之间插入了一个小的SRAM高速缓存存储器，称为L1高速缓存(一级缓存)
            之后增加二级缓存，一些现代机器还有三级高速缓存，前两级为各个CPU核心独享，第三层则为所有核心共享的区域。
        ```
    5. 编写高速缓存友好的代码
        - 概述
        ```
            局部性比较好的程序更容易有较低的不命中率，而不命中率较低的程序往往比不命中率较高的程序运行得更快。
            因此，从具有良好局部性的意义上来说，好的程序员总是应该试着去编写高速缓存友好（cache friendly）的代码。
            下面就是我们用来确保代码高速缓存友好的基本方法。

            1）让最常见的情况运行得快。程序通常把大部分时间都花在少量的核心函数上，而这些函数通常把大部分时间都花在了少量循环上。
            所以要把注意力集中在核心函数里的循环上，而忽略其他部分。
            2）尽量减小每个循环内部的缓存不命中数量。在其他条件（例如加载和存储的总次数）相同的情况下，不命中率较低的循环运行得更快。

            两个关于编写高速缓存友好的代码的重要问题：
                •对局部变量的反复引用是好的，因为编译器能够将它们缓存在寄存器文件中(时间局部性)。
                •步长为1的引用模式是好的，因为存储器层次结构中所有层次上的缓存都是将数据存储为连续的块(空间局部性)。
        ```
    6. 综合：高速缓存对程序性能的影响
        - 概述
        ```
            总结一下我们对存储器山的讨论，存储器系统的性能不是一个数字就能描述的。相反，它是一座时间和空间局部性的山，
            这座山的上升高度差别可以超过一个数量级。明智的程序员会试图构造他们的程序，使得程序运行在山峰而不是低谷。
            目标就是利用时间局部性，使得频繁使用的字从L1中取出，还要利用空间局部性，使得尽可能多的字从一个L1高速缓存行中访问到。

            理解存储器层次结构本质的程序员能够利用这些知识编写出更有效的程序，无论具体的存储系统结构是怎样的。特别地，我们推荐下列技术：
                •将你的注意力集中在内循环上，大部分计算和内存访问都发生在这里。
                •通过按照数据对象存储在内存中的顺序、以步长为1的来读数据，从而使得你程序中的空间局部性最大。
                •一旦从存储器中读入了一个数据对象，就尽可能多地使用它，从而使得程序中的时间局部性最大。
        ```
    ###### 小结
    ```
        基本存储技术包括随机存储器（RAM）、非易失性存储器（ROM）和磁盘。RAM有两种基本类型。
        静态RAM（SRAM）快一些，但是也贵一些，它既可以用做CPU芯片上的高速缓存.也可以用做芯片下的高速缓存。
        动态RAM（DRAM）慢一点，也便宜一些，用做主存和图形帧缓冲区。即使是在关电的时候，ROM也能保持它们的信息，可以用来存储固件。
        旋转磁盘是机械的非易失性存储设备，以每个位很低的成本保存大量的数据，但是其访问时间比DRAM长得多。
        固态硬盘（SSD）基于非易失性的闪存，对某些应用来说，越来越成为旋转磁盘的具有吸引力的替代产品。
        一般而言，较快的存储技术每个位会更贵，而且容量更小。这些技术的价格和性能属性正在以显著不同的速度变化着。
        特别地，DRAM和磁盘访问时间远远大于CPU周期时间。系统通过将存储器组织成存储设备的层次结构来弥补这些差异，
        在这个层次结构中，较小、较快的设备在顶部，较大、较慢的设备在底部。因为编写良好的程序有好的局部性，
        大多数数据都可以从较高层得到服务，结果就是存储系统能以较高层的速度运行，但却有较低层的成本和容量。
        程序员可以通过编写有良好空间和时间局部性的程序来显著地改进程序的运行时间。利用基于SRAM的高速缓存存储器特别重要。
        主要从高速缓存取数据的程序能比主要从内存取数据的程序运行得快得多。
    ```

---
### 第二部分 在系统上运行程序

* 第七章 链接
    - 概述 
    ```
        链接通常是由链接器来默默地处理的，对于那些在编程入门课堂上构造小程序的学生而言，
        链接不是一个重要的议题。那为什么还要这么麻烦地学习关于链接的知识呢？

        •理解链接器将帮助你构造大型程序。构造大型程序的程序员经常会遇到由于缺少模块、缺少库或者不兼容的库版本引起的链接器错误。
        除非你理解链接器是如何解析引用、什么是库以及链接器是如何使用库来解析引用的，否则这类错误将令你感到迷惑和挫败。
        •理解链接器将帮助你避免一些危险的编程错误。Linux链接器解析符号引用时所做的决定可以不动声色地影响你程序的正确性。
        在默认情况下，错误地定义多个全局变量的程序将通过链接器，而不产生任何警告信息。由此得到的程序会产生令人迷惑的运行时行为，
        而且非常难以调试。我们将向你展示这是如何发生的，以及该如何避免它。
        •理解链接将帮助你理解语言的作用域规则是如何实现的。例如，全局和局部变量之间的区别是什么？
        当你定义一个具有static属性的变量或者函数时，实际到底意味着什么？
        •理解链接将帮助你理解其他重要的系统概念。链接器产生的可执行目标文件在重要的系统功能中扮演着关键角色，比如加载和运行程序、虚拟内存、分页、内存映射。
        •理解链接将使你能够利用共享库。多年以来，链接都被认为是相当简单和无趣的。
        然而，随着共享库和动态链接在现代操作系统中重要性的日益加强，链接成为一个复杂的过程，为掌握它的程序员提供了强大的能力。
        比如，许多软件产品在运行时使用共享库来升级压缩包装的(shrink-wrapped)进制程序。还有，大多数Web服务器都依赖于共享库的动态链接来提供动态内容。
    ```
    1. 编译器驱动程序
    ```
        大多数编译系统提供编译器驱动程序（compiler driver）,它代表用户在需要时调用语言预处理器、编译器、汇编器和链接器。
    ```
    2. 静态链接
    ```
        为了构造可执行文件，链接器必须完成两个主要任务：
            •符号解析(symbol resolution).目标文件定义和引用符号，每个符号对应于一个函数、一个全局变量或一个静态变量(即C语言中任何以static属性声明的变量)。
            符号解析的目的是将每个符号引用正好和一个符号定义关联起来。
            •重定位(relocation).编译器和汇编器生成从地址.开始的代码和数据节。链接器通过把每个符号定义与一个内存位置关联起来，
            从而重定位这些节，然后修改所有对这些符号的引用，使得它们指向这个内存位置。链接器使用汇编器产生的重定位条目(relocationentry)的详细指令，
            不加甄别地执行这样的重定位。

            目标文件纯粹是字节块的集合。这些块中，有些包含程序代码，有些包含程序数据，而其他的则包含引导链接器和加载器的数据结构。
            链接器将这些块连接起来，确定被连接块的运行时位置，并且修改代码和数据块中的各种位置。链接器对目标机器了解甚少。
            产生目标文件的编译器和汇编器已经完成了大部分工作。
    ```
    3. 目标文件
    ```
        目标文件有三种形式：
            •可重定位目标文件。包含二进制代码和数据，其形式可以在编译时与其他可重定位目标文件合并起来，创建一个可执行目标文件。
            •可执行目标文件。包含二进制代码和数据，其形式可以被直接复制到内存并执行。
            •共享目标文件。一种特殊类型的可重定位目标文件，可以在加载或者运行时被动态地加载进内存并链接。

            编译器和汇编器生成可重定位目标文件(包括共享目标文件)。链接器生成可执行目标文件。从技术上来说，
            一个目标模块(object module)就是一个字节序列，而一个目标文件(ob- jectfile)就是一个以文件形式存放在磁盘中的目标模块。
    ```
    4. 可重定位目标文件
    ```
        略
    ```
    5. 动态链接共享库
    ```
        共享库(shared library)是致力于解决静态库缺陷的一个现代创新产物。共享库是一个目标模块，在运行或加载时，可以加载到任意的内存地址，
        并和一个在内存中的程序链接起来。这个过程称为动态链接(dynamic linking),是由一个叫做动态链接器(dynamic linker)的程序来执行的。
        共享库也称为共享目标(shared object),在Linux系统中通常用.so后缀来表示。微软的操作系统大量地使用了共享库,它们称为DLL(动态链接库)。

        共享库是以两种不同的方式来“共享”的。首先，在任何给定的文件系统中，对于一个库只有一个.s文件。
        所有引用该库的可执行目标文件共享这个.s文件中的代码和数据，而不是像静态库的内容那样被复制和嵌入到引用它们的可执行的文件中。
        其次，在内存中，一个共享库的.text节的一个副本可以被不同的正在运行的进程共享。
    ```
    6. 从应用程序中加载和链接共享库
    ```
        到目前为止，我们已经讨论了在应用程序被加载后执行前时，动态链接器加载和链接共享库的情景。
        然而，应用程序还可能在它运行时要求动态链接器加载和链接某个共享库，而无需在编译时将那些库链接到应用中。

        动态链接是一项强大有用的技术。下面是一些现实世界中的例子：
        •分发软件。微软Windows应用的开发者常常利用共享库来分发软件更新。他们生成一个共享库的新版本，然后用户可以下载，
        并用它替代当前的版本。下一次他们运行应用程序时，应用将自动链接和加载新的共享库。
        •构建高性能Web服务器。许多Web服务器生成动态内容，比如个性化的Web页面、账户余额和广告标语。
        早期的Web服务器通过使用fork和execve创建一个子进程，并在该子进程的上下文中运行CGI程序来生成动态内容。
        然而，现代高性能的Web服务器可以使用基于动态链接的更有效和完善的方法来生成动态内容。

        其思路是将每个生成动态内容的函数打包在共享库中。当一个来自Web浏览器的请求到达时，服务器动态地加载和链接适当的函数，然后直接调用它，
        而不是使用fork和execve在子进程的上下文中运行函数。函数会一直缓存在服务器的地址空间中，所以只要一个简单的函数调用的开销就可以处理随后的请求了。
        这对一个繁忙的网站来说是有很大影响的。更进一步地说，在运行时无需停止服务器，就可以更新已存在的函数，以及添加新的函数。
    ```
    ###### 小结
    ```
        链接可以在编译时由静态编译器来完成，也可以在加载时和运行时由动态链接器来完成。链接器处理称为目标文件的二进制文件，它有3种不同的形式：
        可重定位的、可执行的和共享的。可重定位的目标文件由静态链接器合并成一个可执行的目标文件，它可以加载到内存中并执行。
        共享目标文件（共享库）是在运行时由动态链接器链接和加载的，或者隐含地在调用程序被加载和开始执行时，或者根据需要在程序调用dlopen库的函数时。

        链接器的两个主要任务是符号解析和重定位，符号解析将目标文件中的每个全局符号都绑定到一个唯一的定义，而重定位确定每个符号的最终内存地址，并修改对那些目标的引用。

        静态链接器是由像GCC这样的编译驱动程序调用的。它们将多个可重定位目标文件合并成一个单独的可执行目标文件。
        多个目标文件可以定义相同的符号，而链接器用来悄悄地解析这些多重定义的规则可能在用户程序中引入微妙的错误。
        多个目标文件可以被连接到一个单独的静态库中。链接器用库来解析其他目标模块中的符号引用。
        许多链接器通过从左到右的顺序扫描来解析符号引用，这是另一个引起令人迷惑的链接时错误的来源。
        加载器将可执行文件的内容映射到内存，并运行这个程序。链接器还可能生成部分链接的可执行目标文件，这样的文件中有对定义在共享庠中的例程和数据的未解析的引用。
        在加载时，加载器将部分链接的可执行文件映射到内存，然后调用动态链接器，它通过加载共享库和重定位程序中的引用来完成链接任务。
        被编译为位置无关代码的共享库可以加载到任何地方，也可以在运行时被多个进程共享。为了加载、链接和访问共享库的函数和数据，应用程序也可以在运行时使用动态链接器。
    ```
---
* 第八章 异常控制流
    - 概述
    ```
        现代系统通过使控制流发生突变来对这些情况做出反应。一般而言，我们把这些突变称为异常控制流(Exceptional Control Flow, ECF)

        作为程序员，理解ECF很重要，这有很多原因：

        •理解ECF将帮助你理解重要的系统概念。ECF是操作系统用来实现I/O、进程和虚拟内存的基本机制。在能够真正理解这些重要概念之前，你必须理解ECF。
        •理解ECF将帮助你理解应用程序是如何与操作系统交互的。应用程序通过使用一个叫做陷阱(trap)或者系统调用(system call)的ECF形式，
        向操作系统请求服务。比如，向磁盘写数据、从网络读取数据、创建一个新进程，以及终止当前进程，都是通过应用程序调用系统调用来实现的。
        理解基本的系统调用机制将帮助你理解这些服务是如何提供给应用的。
        •理解ECF将帮助你编写有趣的新应用程序。操作系统为应用程序提供了强大的ECF机制，用来创建新进程、等待进程终止、通知其他进程系统中的异常事件，
        以及检测和响应这些事件。如果理解了这些ECF机制，那么你就能用它们来编写诸如Unix shell和Web服务器之类的有趣程序了。
        •理解ECF将帮助你理解并发。ECF是计算机系统中实现并发的基本机制。在运行中的并发的例子有：中断应用程序执行的异常处理程序，
        在时间上重叠执行的进程和线程，以及中断应用程序执行的信号处理程序。理解ECF是理解并发的第一步。我们会在第12章中更详细地研究并发。
        •理解ECF将帮助你理解软件异常如何工作。像C++和Java这样的语言通过try. catch以及throw语句来提供软件异常机制。
        软件异常允许程序进行非本地跳转（即违反通常的调用/返回栈规则的跳转）来响应错误情况。
    ```
    1. 异常
    ```
        异常是异常控制流的一种形式，它一部分由硬件实现，一部分由操作系统实现。因为它们有一部分是由硬件实现的，所以具体细节将随系统的不同而有所不同。
    ```
    2. 进程
        - 概述
        ```
            异常是允许操作系统内核提供进程(process)概念的基本构造块，进程是计算机科学中最深刻、最成功的概念之一.
            我们将关注进程提供给应用程序的关键抽象：
            •一个独立的逻辑控制流，它提供一个假象，好像我们的程序独占地使用处理器。
            •一个私有的地址空间，它提供一个假象，好像我们的程序独占地使用内存系统。让我们更深入地看看这些抽象。
        ```
        - 逻辑控制流
        ```
            即使在系统中通常有许多其他程序在运行，进程也可以向每个程序提供一种假象，好像它在独占地使用处理器。
            如果想用调试器单步执行程序，我们会看到一系列的程序计数器(PC)的值，这些值唯一地对应于包含在程序的可执行目标文件中的指令，
            或是包含在运行时动态链接到程序的共享对象中的指令。这个PC值的序列叫做逻时间辑控制流，或者简称逻辑流。

            每个进程执行它的流的一部分，然后被抢占(preempted)(暂时挂起)，然后轮到其他进程。对于一个运行在这些进程之一的上下文中的程序，
            它看上去就像是在独占地使用处理器。唯一的反面例证是，如果我们精确地测量每条指令使用的时间，会发现在程序中一些指令的执行之间，
            CPU好像会周期性地停顿。然而，每次处理器停顿，它随后会继续执行我们的程序，并不改变程序内存位置或寄存器的内容。
        ```
        - 并发流
        ```
            一个逻辑流的执行在时间上与另一个流重叠，称为并发流(concurrent flow),这两个流被称为并发地运行。
        ```
        - 私有地址空间
        ```
            进程为每个程序提供它自己的私有地址空间。一般而言，和这个空间中某个地址相关联的那个内存字节是不能被其他进程读或者写的，
            从这个意义上说，这个地址空间是私有的。尽管和每个私有地址空间相关联的内存的内容一般是不同的，但是每个这样的空间都有相同的通用结构。
            地址空间底部是保留给用户程序的，包括通常的代码、数据、堆和栈段。代码段总是从地址0x400000开始。
            地址空间顶部保留给内核（操作系统常驻内存的部分）。地址空间的这个部分包含内核在代表进程执行指令时（比如当应用程序执行系统调用时）使用的代码、数据和栈。
        ```
        - 用户模式和内核模式
        ```
            为了使操作系统内核提供一个无懈可击的进程抽象，处理器必须提供一种机制，限制一个应用可以执行的指令以及它可以访问的地址空间范围。
            处理器通常是用某个控制寄存器中的一个模式位（mode bit）来提供这种功能的，该寄存器描述了进程当前享有的特权。当设置了模式位时，
            进程就运行在内核模式中（有时叫做超级用户模式）。一个运行在内核模式的进程可以执行指令集中的任何指令，并且可以访问系统中的任何内存位置。
            没有设置模式位时，进程就运行在用户模式中。用户模式中的进程不允许执行特权指令（privilegedinstruction）,
            比如停止处理器、改变模式位，或者发起一个I/O操作。也不允许用户模式中的进程直接引用地址空间中内核区内的代码和数据。

            运行应用程序代码的进程初始时是在用户模式中的。进程从用户模式变为内核模式的唯一方法是通过诸如中断、故障或者陷入系统调用这样的异常。
            当异常发生时，控制传递到异常处理程序，处理器将模式从用户模式变为内核模式。处理程序运行在内核模式中，当它返回到应用程序代码时，
            处理器就把模式从内核模式改回到用户模式。
        ```
        - 上下文切换
        ```
            操作系统内核使用一种称为上下文切换(context switch)的较高层形式的异常控制流来实现多任务。
            内核为每个进程维持一个上下文(context).上下文就是内核重新启动一个被抢占的进程所需的状态。
            它由一些对象的值组成，这些对象包括通用目的寄存器、浮点寄存器、程序计数器、用户栈、状态寄存器、内核栈和各种内核数据结构，
            比如描述地址空间的页表、包含有关当前进程信息的进程表，以及包含进程已打开文件的信息的文件表。

            当内核代表用户执行系统调用时，可能会发生上下文切换。如果系统调用因为等待某个事件发生而阻塞，那么内核可以让当前进程休眠，切换到另一个进程。
        ```
        - 系统调用错误处理
        ```
            应该总是严格处理系统调用错误
        ```
    3. 信号
        - 概述
        ```
            到目前为止对异常控制流的学习中，我们已经看到了硬件和软件是如何合作以提供基本的低层异常机制的。
            我们也看到了操作系统如何利用异常来支持进程上下文切换的异常控制流形式。在本节中，我们将研究一种更高层的软件形式的异常，
            称为Linux信号，它允许进程和内核中断其他进程。

            一个信号就是一条小消息，它通知进程系统中发生了一个某种类型的事件。
        ```
        - 信号术语
        ```
            传送一个信号到目的进程是由两个不同步骤组成的：
            •发送信号。内核通过更新目的进程上下文中的某个状态，发送（递送）一个信号给目的进程。发送信号可以有如下两种原因：
            1）内核检测到一个系统事件，比如除零错误或者子进程终止。
            2）一个进程调用了kill函数（在下一节中讨论），显式地要求内核发送一个信号给目的进程。一个进程可以发送信号给它自己。

            •接收信号。当目的进程被内核强迫以某种方式对信号的发送做出反应时，它就接收了信号。
            进程可以忽略这个信号，终止或者通过执行一个称为信号处理程序(signal han- dler)的用户层函数捕获这个信号。

            一个发出而没有被接收的信号叫做待处理信号(pending signal).在任何时刻，一种类型至多只会有一个待处理信号。
            如果一个进程有一个类型为&的待处理信号，那么任何接下来发送到这个进程的类型为为的信号都不会排队等待；
            它们只是被简单地丢弃。一个进程可以有选择性地阻塞接收某种信号。当一种信号被阻塞时，它仍可以被发送，
            但是产生的待处理信号不会被接收，直到进程取消对这种信号的阻塞。
        ```
        - 发送信号
        ```
            Unix系统提供了大量向进程发送信号的机制。所有这些机制都是基于进程组(processgroup)这个概念的。
            每个进程都只属于一个进程组，进程组是由一个正整数进程组ID来标识的。
            默认地，一个子进程和它的父进程同属于一个进程组。
            信号可以通过类似kill程序或者键盘输入等发送给进程，获取内核发送给目的进程
        ```
        - 接收信号
        ```
            当内核把进程p从内核模式切换到用户模式时（例如，从系统调用返回或是完成了一次上下文切换），它会检查进程P的未被阻塞的待处理信号的集合.
            如果这个集合为空（通常情况下），那么内核将控制传递到P的逻辑控制流中的下一条指令.
        ```
    ###### 小结
    ```
        异常控制流（ECF）发生在计算机系统的各个层次，是计算机系统中提供并发的基本机制。
        在硬件层，异常是由处理器中的事件触发的控制流中的突变。控制流传递给一个软件处理程序，该处理程序进行一些处理，然后返回控制给被中断的控制流。
        有四种不同类型的异常：中断、故障、终止和陷阱。当一个外部I/O设备（例如定时器芯片或者磁盘控制器）设置了处理器芯片上的中断管脚时，
        （对于任意指令）中断会异步地发生。控制返回到故障指令后面的那条指令。一条指令的执行可能导致故障和终止同步发生。
        故障处理程序会重新启动故障指令，而终止处理程序从不将控制返回给被中断的流。
        最后，陷阱就像是用来实现向应用提供到操作系统代码的受控的入口点的系统调用的函数调用。在操作系统层，内核用ECF提供进程的基本概念。
        进程提供给应用两个重要的抽象：
        1）逻辑控制流，它提供给每个程序一个假象，好像它是在独占地使用处理器，
        2）私有地址空间，它提供给每个程序一个假象，好像它是在独占地使用主存。
        在操作系统和应用程序之间的接口处，应用程序可以创建子进程，等待它们的子进程停止或者终止，运行新的程序，以及捕获来自其他进程的信号。
        信号处理的语义是微妙的，并且随系统不同而不同。然而，在与Posix兼容的系统上存在着一些机制，允许程序清楚地指定期望的信号处理语义。
        最后，在应用层，C程序可以使用非本地跳转来规避正常的调用/返回栈规则，并且直接从一个函数分支到另一个函数。
    ```
--- 

* 第九章 虚拟内存
    - 概述
    ```
        一个系统中的进程是与其他进程共享CPU和主存资源的。然而，共享主存会形成一些特殊的挑战。
        随着对CPU需求的增长，进程以某种合理的平滑方式慢了下来。但是如果太多的进程需要太多的内存，那么它们中的一些就根本无法运行。
        当一个程序没有空间可用时，那就是它运气不好了。内存还很容易被破坏。如果某个进程不小心写了另一个进程使用的内存，
        它就可能以某种完全和程序逻辑无关的令人迷惑的方式失败。

        为了更加有效地管理内存并且少出错，现代系统提供了一种对主存的抽象概念，叫做虚拟内存（VM）。
        虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件的完美交互，它为每个进程提供了一个大的、一致的和私有的地址空间。
        通过一个很清晰的机制，虚拟内存提供了三个重要的能力：
        1）它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。
        2）它为每个进程提供了一致的地址空间，从而简化了内存管理。
        3）它保护了每个进程的地址空间不被其他进程破坏。
    ```
    1. 物理和虚拟寻址
    ```
        计算机系统的主存被组织成一个由M个连续的字节大小的单元组成的数组。每字节都有一个唯一的物理地址(Physical Address, PA).
        第一个字节的地址为0,接下来的字节地址为1,再下一个为2,依此类推。给定这种简单的结构，CPU访问内存的最自然的方式就是使用物理地址。
        我们把这种方式称为物理寻址(physicaladdressing)

        早期的PC使用物理寻址，而且诸如数字信号处理器、嵌入式微控制器以及Cray超级计算机这样的系统仍然继续使用这种寻址方式。
        然而，现代处理器使用的是一种称为虚拟寻址(virtual addressing)的寻址形式.

        使用虚拟寻址，CPU通过生成一个虚拟地址(Virtual Address, VA)来访问主存，这个虚拟地址在被送到内存之前先转换成适当的物理地址。
        将一个虚拟地址转换为物理地址的任务叫做地址翻译(address translation).就像异常处理一样，地址翻译需要CPU硬件和操作系统之间的紧密合作。
        CPU芯片上叫做内存管理单元(Memory Management Unit, MMU)的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容由操作系统管理。

    ```
    2. 地址空间
    ```
        地址空间的概念是很重要的，因为它清楚地区分了数据对象（字节）和它们的属性（地址）。
        一旦认识到了这种区别，那么我们就可以将其推广，允许每个数据对象有多个独立的地址，其中每个地址都选自一个不同的地址空间。
        这就是虚拟内存的基本思想。主存中的每字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址。
    ```
    3. 虚拟内存作为缓存的工具
        - 概述
        ```
            概念上而言，虚拟内存被组织为一个由存放在磁盘上的N个连续的字节大小的单元组成的数组。
            每字节都有一个唯一的虚拟地址，作为到数组的索引。磁盘上数组的内容被缓存在主存中。
            和存储器层次结构中其他缓存一样，磁盘（较低层）上的数据被分割成块，这些块作为磁盘和主存（较高层）之间的传输单元。
            VM系统通过将虚拟内存分割为称为虚拟页（Virtual Page, VP）的大小固定的块来处理这个问题。每个虚拟页的大小为P=2n字节。
            类似地，物理内存被分割为物理页（PhysicalPage, PP）,大小也为P字节（物理页也被称为页帧（page frame））。

            在任意时刻，虚拟页面的集合都分为三个不相交的子集：
            •未分配的：VM系统还未分配（或者创建）的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。
            •缓存的：当前已缓存在物理内存中的已分配页。
            •未缓存的：未缓存在物理内存中的已分配页。
        ```
        -  DRAM缓存的组织结构
        ```
            为了有助于清晰理解存储层次结构中不同的缓存概念，我们将使用术语SRAM缓存来表示位于CPU和主存之间的LI、L2和L3高速缓存，
            并且用术语DRAM缓存来表示虚拟内存系统的缓存，它在主存中缓存虚拟页。

            在存储层次结构中，DRAM缓存的位置对它的组织结构有很大的影响。回想一下,DRAM比SRAM要慢大约10倍，而磁盘要比DRAM慢大约100000多倍。
            因此,DRAM缓存中的不命中比起SRAM缓存中的不命中要昂贵得多，这是因为DRAM缓存不命中要由磁盘来服务，而SRAM缓存不命中通常是由基于DRAM的主存来服务的。

            因为大的不命中处罚和访问第一个字节的开销，虚拟页往往很大，通常是4KB〜2MB。由于大的不命中处罚，DRAM缓存是全相联的，
            即任何虚拟页都可以放置在任何的物理页中。不命中时的替换策略也很重要，因为替换错了虚拟页的处罚也非常之高。
            因此，与硬件对SRAM缓存相比，操作系统对DRAM缓存使用了更复杂精密的替换算法。(这些替换算法超出了我们的讨论范围)。
            最后，因为对磁盘的访问时间很长，DRAM缓存总是使用写回，而不是直写。
        ```
        - 页表
        ```
            同任何缓存一样，虚拟内存系统必须有某种方法来判定一个虚拟页是否缓存在DRAM中的某个地方。
            如果是，系统还必须确定这个虚拟页存放在哪个物理页中。如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，
            在物理内存中选择一个牺牲页，并将虚拟页从磁盘复制到DRAM中，替换这个牺牲页。

            这些功能是由软硬件联合提供的，包括操作系统软件、MMU(内存管理单元)中的地址翻译硬件和一个存放在物理内存中叫做页表(page table)的数据结构，
            页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换为物理地址时，都会读取页表。操作系统负责维护页表的内容，以及在磁盘与DRAM之间来回传送页。
        ```
        - 页命中
        ```
            指CPU通过虚拟内存地址访问数据时，内存地址翻译硬件将虚拟内存地址通过一些算法配合常驻主存中的页表来获取真实数据。
            即页表有效位指出所需数据是否缓存在物理内存中。存在即为页命中，反正未命中，操作系统将根据虚拟内存地址去磁盘将数据复制的主存中合适的位置。
        ```
        - 缺页
        ```
            在虚拟内存的习惯说法中，DRAM缓存不命中称为缺页(page fault).
            CPU引用了VP 3中的一个字，VP 3并未缓存在DRAM中。地址翻译硬件从内存中读取PTE3,从有效位推断出VP3未被缓存，并且触发一个缺页异常。
            缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页,在此例中就是存放在PP 3中的VP4。
            如果VP 4已经被修改了，那么内核就会将它复制回磁盘。无论哪种情况，内核都会修改VP4的页表条目，反映出VP4不再缓存在主存中这一事实。


            在虚拟内存的习惯说法中，块被称为页。在磁盘和内存之间传送页的活动叫做交换(swapping)或者页面调度(paging)。
            页从磁盘换入(或者页面调入)DRAM和从DRAM换出(或者页面调出)磁盘。一直等待，直到最后时刻，也就是当有不命中发生时,
            才换入页面的这种策略称为按需页面调度(demand paging)
            所有现代系统都使用的是按需页面调度的方式。
        ```
        - 又是局部性救了我们
        ```
            当我们中的许多人都了解了虚拟内存的概念之后，我们的第一印象通常是它的效率应该是非常低。
            因为不命中处罚很大，我们担心页面调度会破坏程序性能。实际上，虚拟内存工作得相当好，这主要归功于我们的老朋友局部性(locality)

            只要我们的程序有好的时间局部性，虚拟内存系统就能工作得相当好。但是，当然不是所有的程序都能展现良好的时间局部性。
            如果工作集的大小超出了物理内存的大小，那么程序将产生一种不幸的状态，叫做抖动(thrashing),这时页面将不断地换进换出。
            虽然虚拟内存通常是有效的，但是如果一个程序性能慢得像爬一样，那么聪明的程序员会考虑是不是发生了抖动。
        ```
    4. 虚拟内存作为内存管理的工具
        ```
            到目前为止，我们都假设有一个单独的页表，将一个虚拟地址空间映射到物理地址空间。实际上，操作系统为每个进程提供了一个独立的页表，
            因而也就是一个独立的虚拟地址空间。
            注意，多个虚拟页面(不同进程)可以映射到同一个共享物理页面上。

            按需页面调度和独立的虚拟地址空间的结合，对系统中内存的使用和管理造成了深远的影响。
            特别地，VM简化了链接和加载、代码和数据共享，以及应用程序的内存分配。

            •简化链接。独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。
            例如，像我们在图8-13中看到的，一个给定的Linux系统上的每个进程都使用类似的内存格式。
            对于64位地址空间，代码段总是从虚拟地址0x400000开始。数据段跟在代码段之后，中间有一段符合要求的对齐空白。
            栈占据用户进程地址空间最高的部分，并向下生长。这样的一致性极大地简化了链接器的设计和实现，允许链接器生成完全链接的可执行文件，
            这些可执行文件是独立于物理内存中代码和数据的最终位置的。
            •简化加载。虚拟内存还使得容易向内存中加载可执行文件和共享对象文件。要把目标文件中.text和.data节加载到一个新创建的进程中，
            Linux加载器为代码和数据段分配虚拟页，把它们标记为无效的（即未被缓存的），将页表条目指向目标文件中适当的位置。
            有趣的是，加载器从不从磁盘到内存实际复制任何数据。在每个页初次被引用时，要么是CPU取指令时引用的，
            要么是一条正在执行的指令引用一个内存位置时引用的，虚拟内存系统会按照需要自动地调入数据页。
            •简化共享。独立地址空间为操作系统提供了一个管理用户进程和操作系统自身之间共享的一致机制。
            一般而言，每个进程都有自己私有的代码、数据、堆以及栈区域，是不和其他进程共享的。
            在这种情况中，操作系统创建页表，将相应的虚拟页映射到不连续的物理页面。然而，在一些情况中，还是需要进程来共享代码和数据。
            例如，每个进程必须调用相同的操作系统内核代码，而每个C程序都会调用C标准库中的程序，比如printf。
            操作系统通过将不同进程中适当的虚拟页面映射到相同的物理页面，从而安排多个进程共享这部分代码的一个副本，
            而不是在每个进程中都包括单独的内核和C标准库的副本。

            •简化内存分配。虚拟内存为向用户进程提供一个简单的分配额外内存的机制。当一个运行在用户进程中的程序要求额外的堆空间时（如调用malloc的结果），
            操作系统分配一个适当数字（例如为）个连续的虚拟内存页面，并且将它们映射到物理内存中任意位置的为个任意的物理页面。
            由于页表工作的方式，操作系统没有必要分配为个连续的物理内存页面。页面可以随机地分散在物理内存中。
        ```
    5. 虚拟内存作为内存保护的工具
    ```
        任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问。不应该允许一个用户进程修改它的只读代码段。
        而且也不应该允许它读或修改任何内核中的代码和数据结构。不应该允许它读或者写其他进程的私有内存，
        并且不允许它修改任何与其他进程共享的虚拟页面，除非所有的共享者都显式地允许它这么做(通过调用明确的进程间通信系统调用)

        就像我们所看到的，提供独立的地址空间使得区分不同进程的私有内存变得容易。并且，地址翻译机制可以以一种自然的方式扩展到提供更好的访问控制。
        因为每次CPU生成一个地址时，地址翻译硬件都会读一个PTE,所以通过在PTE添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单。
    ```
    6. 地址翻译
    ```
        当页面命中时，CPU硬件执行的步骤。
            •第1步：处理器生成一个虚拟地址，并把它传送给MMU。
            •第2步：MMU生成PTE地址，并从高速缓存/主存请求得到它。
            •第3步：高速缓存/主存向MMU返回PTE。
            •第4步：MMU构造物理地址，并把它传送给高速缓存/主存。
            •第5步：高速缓存/主存返回所请求的数据字给处理器。

        页面命中完全是由硬件来处理的，与之不同的是，处理缺页要求硬件和操作系统内核协作完成
            前三步与上面一致
            •第4步：PTE中的有效位是零，所以MMU触发了一次异常，传递CPU中的控制到操作系统内核中的缺页异常处理程序。
            •第5步：缺页处理程序确定出物理内存中的牺牲页，如果这个页面已经被修改了，则把它换出到磁盘。
            •第6步：缺页处理程序页面调入新的页面，并更新内存中的PTE。
            •第7步：缺页处理程序返回到原来的进程，再次执行导致缺页的指令。CPU将引起缺页的虚拟地址重新发送给MMU。
            因为虚拟页面现在缓存在物理内存中，所以就会命中，在MMU执行了之前的步骤之后，主存就会将所请求字返回给处理器。

        多级页表: 每个进程增加一层二级页表。
        这种方法从两个方面减少了内存要求。第一，如果一级页表中的一个PTE是空的,那么相应的二级页表就根本不会存在。
        这代表着一种巨大的潜在节约，因为对于一个典型的程序，4GB的虚拟地址空间的大部分都会是未分配的。
        第二，只有一级页表才需要总是在主存中；虚拟内存系统可以在需要时创建、页面调入或调出二级页表，这就减少了主存的压力；
        只有最经常使用的二级页表才需要缓存在主存中。
    ```
    7. Linux虚拟内存系统
    ```
        
    ```
