* 第一章 计算机系统漫游
    1. 总述
    ```
        计算机系统是由硬件和系统软件组成的,它们共同工作来运行应用程序。虽然系统的具体实现方式随着时间不断变化,但是系统内在的概念却没有改变。
        所有计算机系统都有相似的硬件和软件组件,它们又执行着相似的功能。一些程序员希望深人了解这些组件是如何工作的以及这些组件是如何影响程序的正确性和性能的,以此来提高自身的技能。
        本书便是为这些读者而写的。
    ```
    2. 信息就是位+上下文
    ```
        源程序实际上就是一个由值0和1组成的位(又称为比特)序列,8个位被组织成一组,称为字节。每个字节表示程序中的某些文本字符。
        大部分的现代计算机系统都使用AScⅡ标准来表示文本字符,这种方式实际上就是用一个唯一的单字节大小的整数值e来表示每个字符。
    ```
    3. 程序被其他程序翻译成不同的格式
    ```
        这个翻译过程可分为四个阶段完成:
        1. 预处理阶段。预处理器(cpp)根据以字符#开头的命令,修改原始的C程序。
        2. 编译阶段。编译器(ccl)将文本文件hello.i翻译咸文本文件hello.s,它包含一个汇编语言程序。
        3. 汇编阶段。接下来,汇编器(as)将he||○.S翻译成机器语言指令,把这些指令打包成一种叫做可重定位目标程.并将结果存入二进制文件.
        4. 链接阶段。请注意,hello程序调用了printf函数,它是每个C编译器都提供的标准C库中的一个函数. 
        printf函数存在于一个名为printf.o的单独的预编译好了的目标文件中,而这个文件必须以某种方式合并到我们的hello.o程序中。
        链接器(1d)就负责处理这种合并。结果就得到hello文件,它是一个可执行目标文件(或者简称为可执行文件),
        可以被加载到内存中,由系统执行。
    ```
    4. 了解编译系统如何工作是大有益处的
    ```
        对于像hello.c这样简单的程序,我们可以依靠编译系统生成正确有效的机器代码。但是,有一些重要的原因促使程序员必须知道编译系统是如何工作的。
        1. 优化程序性能。现代编译器都是成熟的工具,通常可以生成很好的代码。作为程序员,我们无须为了写出高效代码而去了解编译器的内部工作。
        2. 理解链接时出现的错误。
        3. 避兔安全漏洞。多年来,缓冲区溢出错误是造成大多数网络和Intemet服务器上安全漏洞的主要原因。
        存在这些错误是因为很少有程序员能够理解需要限制从不受信任的源接收数据的数量和格式。
        学习安全编程的第一步就是理解数据和控制信息存储在程序栈上的方式会引起的后果。
    ```
    5. 处理带读并解释储存在内存中的指令
        - 总述
        ```
            此刻,hello.c源程序已经被编译系统翻译成了可执行目标文件hel|o,并被存放在磁盘上。
            要想在Unix系统上运行该可执行文件,我们将它的文件名输人到称为shell的应用程序中:

            sheⅡ是一个命令行解释器,它输出一个提示符,等待输人一个命令行,然后执行这个命令。
            如果该命令行的第一个单词不是一个内置的shell命令,那么shell就会假设这是一个可执行文件的名字,
            它将加载并运行这个文件。所以在此例中,sheⅡ将加载并运行hello程序,然后等待程序终止. 
            hell0程序在屏幕上输出它的消息,然后终止o shell随后输出一个提示符,等待下一个输人的命令行。
        ```
        - 系统的硬件组成
        ```
            1.总线
            贯穿整个系统的是一组电子管道,称作总线,它携带信息字节并负责在各个部件间传递。
            通常总线被设计成传送定长的字节块,也就是字(word)。字中的字节数(即字长)是一个基本的系统参数,各个系统中都不尽相同。
            现在的大多数机器字长要么是4个字节(32位),要么是8个字节(64位)
            2. I/O设备
            Ⅰ/o(输人/输出)设备是系统与外部世界的联系通道。
            我们的示例系统包括四个Ⅰ/o设备:作为用户输人的键盘和鼠标,作为用户输出的显示器,以及用于长期存储数据和程序的磁盘驱动器(简单地说就是磁盘)。
            最开始,可执行程序hello就存放在磁盘上。
            3. 主存
            主存是一个临时存储设备,在处理器执行程序时,用来存放程序和程序处理的数据。
            4. 处理器
            中央处理单元(CPU),简称处理器,是解释(或执行)存储在主存中指令的引擎。
        ```
        - 高速缓存至关重要
        ```
            这个简单的示例揭示了一个重要的间题,即系统花费了大量的时间把信息从一个地方挪到另一个地方.
            hello程序的机器指令最初是存放在磁盘上,当程序加载时,它们被复制到主存;当处理器运行程序时,指令又从主存复制到处理器。
            相似地,数据串“hello,WOr|d/n#开始时在磁盘上,然后被复制到主存,最后从主存上复制到显示设备。
            从程序员的角度来看,这些复制就是开销,减慢了程序“真正”的工作。
            因此,系统设计者的一个主要目标就是使这些复制操作尽可能快地完成。

            根据机械原理,较大的存储设备要比较小的存储设备运行得慢,而快速设备的造价远高于同类的低速设备。
            比如说,一个典型系统上的磁盘驱动器可能比主存大1000倍,但是对处理器而言,
            从磁盘驱动器上读取一个字的时间开销要比从主存中读取的开销大1000万倍。

            类似地,一个典型的寄存器文件只存储几百字节的信息,而主存里可存放几十亿字节。
            然而,处理器从寄存器文件中读数据比从主存中读取几乎要快100倍。
            更麻烦的是,随着这些年半导体技术的进步,这种处理器与主存之间的差距还在持续增大。
            加快处理器的运行速度比加快主存的运行速度要容易和便宜得多。

            针对这种处理器与主存之间的差异,系统设计者采用了更小更快的存储设备,
            称为高速缓存存储器(cachememory,简称为cache或高速缓存),作为暂时的集结区域,存放处理器近期可能会需要的信息。

            本书得出的重要结论之一就是,意识到高速缓存存储器存在的应用程序员能够利用高速缓存将程序的性能提高一个数量级。
        ```
        - 存储设备形成层次结构
        ```
            在处理器和一个较大较慢的设备(例如主存)之间插人一个更小更快的存储设备(例如高速缓存)的想法已经成为一个普遍的观念。
            实际上,每个计算机系统中的存储设备都被组织成了一个存储器层次结构,在这个层次结构中,从上至下,
            设备的访问速度越来越慢、容量越来越大,并且每字节的造价也越来越便宜。寄存器文件在层次结构中位于最顶部,
            也就是第0级或记为LO.这里我们展示的是三层高速缓存Ll到L3,占据存储器层次结构的第1层到第3层。主存在第4层,以此类推。

            存储器层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存。
            因此,寄存器文件就是Ll的高速缓存,Ll是L2的高速缓存,L2是L3的高速缓存,L3是主存的高速缓存,而主存又是磁盘的高速缓存。
            在某些具有分布式文件系统的网络系统中,本地磁盘就是存储在其他系统中磁盘上的数据的高速缓存。

            正如可以运用不同的高速缓存的知识来提高程序性能一样,程序员同样可以利用对整个存储器层次结构的理解来提高程序性能。
        ```
        - 操作系统管理硬件
        ```
            让我们回到hell〇程序的例子。当shell加载和运行hello程序时,以及hello程序输出自已的消息时,
            Shell和hell〇程序都没有直接访问键盘、显示器、磁盘或者主存。
            取而代之的是,它们依靠操作系统提供的服务。我们可以把操作系统看成是应用程序和硬件之间插人的一层软件,
            所有应用程序对硬件的操作尝试都必须通过操作系统。

            1. 进程
            进程是操作系统对一个正在运行的程序的一种抽象。在一个系统上可以同时运行多个进程,
            而每个进程都好像在独占地使用硬件。而并发运行,则是说一个进程的指令和另一个进程的指令是交错执行的。
            在大多数系统中,需要运行的进程数是多于可以运行它们的CPU个数的。
            传统系统在一个时刻只能执行一个程序,而先进的多核处理器同时能够执行多个程序。
            无论是在单核还是多核系统中,一个CPU看上去都像是在并发地执行多个进程,这是通过处理器在进程间切换来实现的。
            操作系统实现这种交错执行的机制称为上下文切换。

            操作系统保持跟踪进程运行所需的所有状态信息。这种状态,也就是上下文,包括许多信息,比如PC和寄存器文件的当前值,以及主存的内容。
            在任何一个时刻,单处理器系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程时,就会进行上下文切换,
            即保存当前进程的上下文、恢复新进程的上下文,然后将控制权传递到新进程。新进程就会从它上次停止的地方开始。
            2. 线程
            尽管通常我们认为一个进程只有单一的控制流,但是在现代系统中,一个进程实际上可以由多个称为线程的执行单元组成,
            每个线程都运行在进程的上下文中,并共享同样的代码和全局数据。由于网络服务器中对并行处理的需求,
            线程成为越来越重要的编程模型,因为多线程之间比多进程之间更容易共享数据,也因为线程一般来说都比进程更高效。
            当有多处理器可用的时候,多线程也是一种使得程序可以运行得更快的方法
            3. 虚拟内存
            虚拟内存是一个抽象概念,它为每个进程提供了一个假象,即每个进程都在独占地使用主存。
            每个进程看到的内存都是一致的,称为虚拟地址空间。

            每个进程看到的虚拟地址空间由大量准确定义的区构成,每个区都有专门的功能。
            在本书的后续章节你将学到更多有关这些区的知识,但是先简单了解每一个区是非常有益的。
            我们从最低的地址开始,逐步向上介绍。
                1. 程序代码和数据 
                对所有的进程来说,代码是从同一固定地址开始,紧接着的是和C全局变量相对应的数据位置。
                代码和数据区是直接接照可执行目标文件的内容初始化的.
                2.堆
                代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始运行时就被指定了大小,
                与此不同,当调用像malloc和free这样的C标准库函数时,堆可以在运行时动态地扩展和收缩
                3.共享库。
                大约在地址空间的中间部分是一块用来存放像C标准库和数学库这样的共享库的代码和数据的区域。
                4. 栈。
                位于用户虚拟地址空间顶部的是用户栈,编译器用它来实现函数调用。
                和堆一样,用户栈在程序执行期间可以动态地扩展和收缩。
                特别地,每次我们调用一个函数时,栈就会增长;从一个函数返回时,栈就会收缩。
                5. 内核虚拟内存
                地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。
                相反,它们必须调用内核来执行这些操作。

                虚拟内存的运作需要硬件和操作系统软件之间精密复杂的交互,包括对处理器生成的每个地址的硬件翻译。
                基本思想是把一个进程虚拟内存的内容存储在磁盘上,然后用主存作为磁盘的高速缓存。
        ```
        - 文件
        ```
            文件就是字节序列,仅此而已。
            文件就是字节序列,仅此而已。每个Ⅰ/o设备,包括磁盘、键盘、显示器,甚至网络,都可以看成是文件。
            系统中的所有输人输出都是通过使用一小组称为UnixI/o的系统函数调用读写文件来实现的。
        ```
    6. 系统之间利用网络通信
    ```
        我们一直是把系统视为一个孤立的硬件和软件的集合体。实际上,现代系统经常通过网络和其他系统连接到一起。
        从一个单独的系统来看,网络可视为一个Ⅰ/o设备。
        当系统从主存复制一串字节到网络适配器时,数据流经过网络到达另一台机器,而不是比如说到达本地磁盘驱动器。
        相似地,系统可以读取从其他机器发送来的数据,并把数据复制到自已的主存.
    ```
    7. 重要主题
        - 总述
        ```
            在此,小结一下我们旋风式的系统漫游。这次讨论得出一个很重要的观点,那就是系统不仅仅只是硬件。
            系统是硬件和系统软件互相交织的集合体,它们必须共同协作以达到运行应用程序的最终目的。
            本书的余下部分会讲述硬件和软件的详细内容,通过了解这些详细内容,你可以写出更快速、更可靠和更安全的程序。
        ```
        - Amdahl定律
        ```
            律的主要观点一要想显著加速整个系统,必须提升全系统中相当大的部分的速度。
            Amdahl定律描述了改善任何过程的一般原则。除了可以用在加速计算机系统方面之外,它还可以用在公司试图降低刀片制造成本,
            或学生想要提高自已的绩点平均值等方面。也许它在计算机世界里是最有意义的,
            在这里我们常常把性能提升2倍或更高的比例因子。这么高的比例因子只有通过优化系统的大部分组件才能获得。
        ```
        - 并发和并行
        ```
            数字计算机的整个历史中,有两个需求是驱动进步的持续动力:一个是我们想要计算机做得更多,
            另一个是我们想要计算机运行得更快。当处理器能够同时做更多的事情时,这两个因素都会改进。
            我们用的术语并发(concurrency)是一个通用的概念,指一个同时具有多个活动的系统;
            而术语并行(para11elism)指的是用并发来使一个系统运行得更快。并行可以在计算机系统的多个抽象层次上运用。
            在此,我们按照系统层次结构中由高到低的顺序重点强调三个层次。
            1. 线程级并发
            构建在进程这个抽象之上,我们能够设计出同时有多个程序执行的系统,这就导致了并发。使用线程,我们甚至能够在一个进程中执行多个控制流。
            多处理器的使用可以从两方面提高系统性能。首先,它减少了在执行多个任务时模拟并发的需要。
            正如前面提到的,即使是只有一个用户使用的个人计算机也需要并发地执行多个活动。
            其次,它可以使应用程序运行得更快,当然,这必须要求程序是以多线程方式来书写的,这些线程可以并行地高效执行。
            2. 指令级并行
            在较低的抽象层次上,现代处理器可以同时执行多条指令的属性称为指令级并行。
            3. 单指令、多数据并行
            在最低层次上,许多现代处理器拥有特殊的硬件,允许一条指令产生多个可以并行执行的操作,这种方式称为单指令、多数据,即sIMD并行。
        ```
        - 计算机系统中抽象的重要性
        ```
            抽象的使用是计算机科学中最为重要的概念之一。例如,为一组函数规定一个简单的应用程序接日(API)就是一个很好的编程习惯,
            程序员无须了解它内部的工作便可以使用这些代码。不同的编程语言提供不同形式和等级的抽象支持,
            例如Java类的声明和C语言的函数原型。

            在学习操作系统时,我们介绍了三个抽象:文件是对Ⅰ/o设备的拍象,虚拟内存是对程序存储器的抽象,
            而进程是对一个正在运行的程序的抽象。我们再增加一个新的抽象:
            虚拟机,它提供对整个计算机的抽象,包括操作系统、处理器和程序。
        ```
    ###### 小结
    ```
        计算机系统是由硬件和系统软件组成的,它们共同协作以运行应用程序。
        计算机内部的信息被表示为一组组的位,它们依据上下文有不同的解释方式。
        程序被其他程序翻译成不同的形式,开始时是ASCⅡ文本,然后被编译器和链接器翻译成二进制可执行文件。

        处理器读取并解释存放在主存里的二进制指令。因为计算机花费了大量的时间在内存、 I/o设备和CPU寄存器之间复制数据,
        所以将系统中的存储设备划分成层次结构一CPU寄存器在顶部,接着是多层的硬件高速缓存存储器、 DRAM主存和磁盘存储器。
        在层次模型中,位于更高层的存储设备比低层的存储设备要更快,单位比特造价也更高。
        层次结构中较高层次的存储设备可以作为较低层次设备的高速缓存。
        通过理解和运用这种存储层次结构的知识,程序员可以优化C程序的性能。

        操作系统内核是应用程序和硬件之间的媒介。它提供三个基本的抽象:
            1)文件是对Ⅰ/o设备的抽象;
            2)虚拟内存是对主存和磁盘的抽象;
            3)进程是处理器、主存和Ⅰ/o设备的抽象。
        最后,网络提供了计算机系统之间通信的手段。从特殊系统的角度来看,网络就是一种Ⅰ/o设备。
    ```
---
### 第一部分 程序结构和执行
```
    我们对计算机系统的探索是从学习计算机本身开始的,它由处理器和存储器子系统纽成。
    在核心部分,我们需要方法来表示基本数据类型,比如整数和实数运算的近似值。
    然后,我们考虑机器级指令如何操作这样的数据,以及编译器又如何将c程序翻译成这样的指令。
    接下来,研究几种实现处理器的方法,帮助我们更好地了解硬件资源如何被用来执行指令。
    一旦理解了编译器和机器级代码,我们就能了解如何通过编写C程序以及编译它们来最大化程序的性能。
    本部分以存储器子系统的设计作为结束,这是现代计算机系统最复杂的部分之一。本书的这一部分将领着你深入了解如何表示和执行应用程序。
    你将学会一些技巧,来帮助你写出安全、可靠且充分利用计算资源的程序。
```
* 第二章 信息的表示和处理
    1. 信息存储
        - 概述
        ```
            大多数计算机使用8位的块,或者字节(byte),作为最小的可寻址的内存单位,而不是访问内存中单独的位。
            机器级程序将内存视为一个非常大的字节数组,称为虚拟内存(virtualmemory)。
            内存的每个字节都由一个唯一的数字来标识,称为它的地址(address),
            所有可能地址的集合就称为虚拟地址空间(virtualaddressspace)。
            顾名思义,这个虚拟地址空间只是一个展现给机器级程序的概念性映像。
        ```
        - 十六进制表示法
        ```
            在C语言中,以Ox或OX开头的数字常量被认为是十六进制的值。字
        ```
        - 字数据大小
        ```
            每台计算机都有一个字长(wordsize),指明指针数据的标称大小(nominalsize)。
            因为虚拟地址是以这样的一个字来编码的,所以字长决定的最重要的系统参数就是虚拟地址空间的最大大小。
            32位字长系统,对应虚拟内存一般为4GB,而64位系统则可达到16GB

            程序员应该力图使他们的程序在不同的机器和编译器上可移植。可移植性的一个方面就是使程序对不同数据类型的确切大小不敏感.

            随着64位机器的日益普及,在将这些程序移植到新机器上时,许多隐藏的对字长的依赖性就会显现出来,成为错误。
            比如,许多程序员假设一个声明为int类型的程序对象能被用来存储一个指针。这在大多数32位的机器上能正常工作,但是在一台64位的机器上却会导致问题。
        ```
        - 寻址和字节顺序
        ```
            对于跨越多字节的程序对象,我们必须建立两个规则:这个对象的地址是什么,以及在内存中如何排列这些字节。
            在几乎所有的机器上,多字节对象都被存储为连续的字节序列,对象的地址为所使用字节中最小的地址。

            对于大多数应用程序员来说,其机器所使用的字节顺序是完全不可见的。无论为哪种类型的机器所编译的程序都会得到同样的结果。
            不过有时候,字节顺序会成为问题。首先是在不同类型的机器之间通过网络传送二进制数据时,
            一个常见的问题是当小端法机器产生的数据被发送到大端法机器或者反过来时,接收程序会发现,字里的字节成了反序的。
            为了避免这类问题,网络应用程序的代码编写必须遵守已建立的关于字节顺序的规则,以确保发送方机器将它的内部表示转换成网络标准,
            而接收方机器则将网络标准转换为它的内部表示。
        ```
        - 表示字符串
        ```
            与字节顺序和字大小规则无关。因而,文本数据比二进制数据具有更强的平台独立性。
        ```
        - 表示代码
        ```
            我们发现指令编码是不同的。不同的机器类型使用不同的且不兼容的指令和编码方式。
            即使是完全一样的进程,运行在不同的操作系统上也会有不同的编码规则,因此二进制代码是不兼容的。二进制代码很少能在不同机器和操作系统组合之间移植。

            计算机系统的一个基本概念就是,从机器的角度来看,程序仅仅只是字节序列。机器没有关于原始源程序的任何信息,除了可能有些用来帮助调试的辅助表以外。
            在第3章学习机器级编程时,我们将更清楚地看到这一点.
        ```
    2. 整数表示
        - 概述
        ```
            在本节中,我们描述用位来编码整数的两种不同的方式:一种只能表示非负数,而另一种能够表示负数、零和正数。
            后面我们将会看到它们在数学属性和机器级实现方面密切相关。
            我们还会研究扩展或者收缩一个已编码整数以适应不同长度表示的效果。
        ```
        - 整型数据类型
        ```
            C语言支持多种整型数据类型--表示有限范围的整数。

            示,为这些不同的大小分配的字节数根据程序编译为32位还是64位而有所不同。
            根据字节分配,不同的大小所能表示的值的范围是不同的。这里给出来的唯一一个与机器相关的取值范围是大小指示符long的。
            大多数64位机器使用8个字节的表示,比32位机器上使用的4个字节的表示的取值范围大很多。
            
            一个很值得注意的特点是取值范围不是对称的一负数的范围比整数的范围大1.当我们考虑如何表示负数的时候,会看到为什么会这样.

        ```
        - 无符号数的编码
        ```
            我们已经看到了许多无符号运算的细微特性,尤其是有符号数到无符号数的隐式转换,会导致错误或者漏洞的方式。
            避免这类错误的一种方法就是绝不使用无符号数。实际上,除了C以外很少有语言支持无符号整数。
            很明显,这些语言的设计者认为它们带来的麻烦要比益处多得多。比如,Java只支持有符号整数,并且要求以补码运算来实现。
            正常的右移运算符>>被定义为执行算术右移。特殊的运算符>>>被指定为执行逻辑右移。
            当我们想要把字仅仅看做是位的集合而没有任何数字意义时,无符号数值是非常有用的。
            例如,往一个字中放人描述各种布尔条件的标记(flag)时,就是这样。
            地址自然地就是无符号的,所以系统程序员发现无符号类型是很有帮助的。
            当实现模运算和多精度运算的数学包时,数字是由字的数组来表示的,无符号值也会非常有用.
        ```
    3. 整数运算
        - 概述
        ```
            许多刚人门的程序员非常惊奇地发现,两个正数相加会得出一个负数,而比较表达式x<y和比较表达式x-y<0会产生不同的结果。
            这些属性是由于计算机运算的有限性造成的。理解计算机运算的细微之处能够帮助程序员编写更可靠的代码.
        ```
        - 关于整数运算的最后思考
        ```
            正如我们看到的,计算机执行的“整数″运算实际上是一种模运算形式。表示数字的有限字长限制了可能的值的取值范围,结果运算可能溢出。
            我们还看到,补码表示提供了一种既能表示负数也能表示正数的灵活方法,同时使用了与执行无符号算术相同的位级实现,
            这些运算包括像加法、减法、乘法,甚至除法,无论运算数是以无符号形式还是以补码形式表示的,都有完全一样或者非常类似的位级行为。
        ```
    ###### 小结
    ```
        计算机将信息编码为位(比特),通常组织成字节序列。有不同的编码方式用来表示整数、实数和字符串。
        不同的计算机模型在编码数字和多字节数据中的字节顺序时使用不同的约定.
        C语言的设计可以包容多种不同字长和数字编码的实现0 64位字长的机器逐渐普及,并正在取代统治市场长达30多年的32位机器。
        由于64位机器也可以运行为32位机器编译的程序,我们的重点就放在区分32位和64位程序,而不是机器本身. 
        64位程序的优势是可以突破32位程序具有的4GB地址限制。

        由于编码的长度有限,与传统整数和实数运算相比,计算机运算具有非常不同的属性。
        当超出表示范围时,有限长度能够引起数值溢出。当浮点数非常接近于0.0,从而转换成零时,也会下溢。

        必须非常小心地使用浮点运算,因为浮点运算只有有限的范围和精度,而且并不遵守普遍的算术属性,比如结合性。
    ```
---
* 第三章 程序的机器级表示
    1. 总述
    ```
        计算机执行机器代码,用字节序列编码低级的操作,包括处理数据、管理内存、读写存储设备上的数据,以及利用网络通信。
        编译器基于编程语言的规则、目标机器的指令集和操作系统遵循的惯例,经过一系列的阶段生成机器代码.
        GCC C语言编译器以汇编代码的形式产生输出,汇编代码是机器代码的文本表示,给出程序中的每一条指令。
        然后GCC调用汇编器和链接器,根据汇编代码生成可执行的机器代码。
        在本章中,我们会近距离地观察机器代码,以及人类可读的表示一汇编代码。
        tips: Golang 自带的编译器GC(golang compiler) 与GCC 提供的GCCGO 存在一些不同,选择编译器时应该根据项目定义及需求来考虑
    ```
    2. 程序编码
        - 机器级代码
        ```
        x86-64的机器代码和原始的C代码差别非常大。一些通常对C语言程序员隐藏的处理器状态都是可见的:
            ●程序计数器(通常称为“PC”,在x86-64中用%rip表示)给出将要执行的下一条指令在内存中的地址。
            ●整数寄存器文件包含16个命名的位置,分别存储64位的值。这些寄存器可以存储地址(对应于C语言的指针)或整数数据。
            有的寄存器被用来记录某些重要的程序状态,而其他的寄存器用来保存临时数据,例如过程的参数和局部变量,以及函数的返回值。
            ●条件码寄存器保存着最近执行的算术或逻辑指令的状态信息。它们用来实现控制或数据流中的条件变化,比如说用来实现if和while语旬。
            ●一组向量寄存器可以存放一个或多个整数或浮点数值。

            虽然C语言提供了一种模型,可以在内存中声明和分配备种数据类型的对象,但是机器代码只是简单地将内存看成一个很大的、按字节寻址的数组. 
            C语言中的聚合数据类型,例如数组和结构,在机器代码中用一组连续的字节来表示。
            即使是对标量数据类型,汇编代码也不区分有符号或无符号整数,不区分备种类型的指针,甚至于不区分指针和整数。
            程序内存包含:程序的可执行机器代码,操作系统需要的一些信息,用来管理过程调用和返回的运行时栈,以及用户分配的内存块(比如说用malloc库函数分配的)。
            正如前面提到的,程序内存用虚拟地址来寻址。在任意给定的时刻,只有有限的一部分虚拟地址被认为是合法的。
            例如,x86-64的虚拟地址是由64位的字来表示的。在目前的实现中,这些地址的高16位必须设置为0,所以一个地址实际上能够指定的是248或64TB范围内的一个字节。
            较为典型的程序只会访间几兆字节或几千兆字节的数据。操作系统负责管理虚拟地址空间,将虚拟地址翻译成实际处理器内存中的物理地址。
            一条机器指令只执行一个非常基本的操作。例如,将存放在寄存器中的两个数字相加,在存储器和寄存器之间传送数据,或是条件分支转移到新的指令地址。
            编译器必须产生这些指令的序列,从而实现(像算术表达式求值、循环或过程调用和返回这样的)程序结构。
        ```
        - 访问信息
        ```
            一个x86-64的中央处理单元(CPU)包含一组16个存储64位值的通用目的寄存器。这些寄存器用来存储整数数据和指针。
            
            指令可以对这16个寄存器的低位字节中存放的不同大小的数据进行操作。
            字节级操作可以访问最低的字节,16位操作可以访问最低的2个字节,32位操作可以访问最低的4个字节,而64位操作可以访问整个寄存器。

            tips: 大多数高级语言的数据类型自动扩所容都是基于底层的存储空间访问规则来的. 比如golang 的切片扩容等
            
            在常见的程序里不同的寄存器扮演不同的角色。其中最特别的是栈指针持sp,用来指明运行时栈的结束位置。
            有些程序会明确地读写这个寄存器。另外15个寄存器的用法更灵活。少量指令会使用某些特定的寄存器。
            更重要的是,有一组标准的编程规范控制着如何使用寄存器来管理栈、传递函数参数、从函数的返回值,以及存储局部和临时数据。
            我们会在描述过程的实现时(特别是在3.7节中),讲述这些惯例.
        ```
        - 数据传送指令
        ```
            最频繁使用的指令是将数据从一个位置复制到另一个位置的指令。
            操作数表示的通用性使得一条简单的数据传送指令能够完成在许多机器中要好几条不同指令才能完成的功能。
            我们会介绍多种不同的数据传送指令,它们或者源和目的类型不同,或者执行的转换不同,或者具有的一些副作用不同.

            源操作数指定的值是一个立即数,存储在寄存器中或者内存中。目的操作数指定一个位置,要么是一个寄存器或者,要么是一个内存地址. 
            x86-64加了一条限制,传送指令的两个操作数不能都指向内存位置。将一个值从一个内存位置复制到另一个内存位置需要两条指令:
            第一条指令将源值加载到寄存器中,
            第二条将该寄存器值写人目的位置。
        ```
        - 过程
        ```
            过程是软件中一种很重要的抽象。它提供了一种封装代码的方式,用一组指定的参数和一个可选的返回值实现了某种功能。
            然后,可以在程序中不同的地方调用这个函数。设计良好的软件用过程作为抽象机制,隐藏某个行为的具体实现,
            同时又提供清晰简洁的接日定义,说明要计算的是哪些值,过程会对程序状态产生什么样的影响。
            不同编程语言中,过程的形式多样:函数(function),方法(method),子例程(subroutine),处理函数(handler)等等,但是它们有一些共有的特性。

            要提供对过程的机器级支持,必须要处理许多不同的属性。为了讨论方便,假设过程P调用过程Q,Q执行后返回到P.
            这些动作包括下面一个或多个机制:
            传递控制。在进人过程Q的时候,程序计数器必须被设置为Q的代码的起始地址,然后在返回时,要把程序计数器设置为p中调用Q后面那条指令的地址。
            传递数据. p必须能够向Q提供一个或多个参数,Q必须能够向p返回一个值。
            分配和释放内存。在开始时,Q可能需要为局部变量分配空间,而在返回前,又必须释放这些存储空间o
        ```
        - 运行时栈
        ```
            C语言过程调用机制的一个关键特性(大多数其他语言也是如此)在于使用了栈数据结构提供的后进先出的内存管理原则。
            在过程P调用过程Q的例子中,可以看到当Q在执行时,P以及所有在向上追溯到p的调用链中的过程,都是暂时被挂起的。
            当Q运行时,它只需要为局部变量分配新的存储空间,或者设置到另一个过程的调用。
            另一方面,当Q返回时,任何它所分配的局部存储空间都可以被释放。
            因此,程序可以用栈来管理它的过程所需要的存储空间,栈和程序寄存器存放着传递控制和数据、分配内存所需要的信息。
            当P调用Q时,控制和数据信息添加到栈尾。当p返回时,这些信息会释放掉。

            为了提高空间和时间效率,x86-64过程只分配自已所需要的栈帧部分。例如,许多过程有6个或者更少的参数,那么所有的参数都可以通过寄存器传递。
            因此,图3-25中画出的某些栈帧部分可以省略。实际上,许多函数甚至根本不需要栈帧。
            当所有的局部变量都可以保存在寄存器中,而且该函数不会调用任何其他函数(有时称之为叶子过程,此时把过程调用看做树结构)时,就可以这样处理。
            例如,到目前为止我们仔细审视过的所有函数都不需要栈帧.
        ```
        - 数据传送
        ```
            当调用一个过程时,除了要把控制传递给它并在过程返回时再传递回来之外,过程调用还可能包括把数据作为参数传递,而从过程返回还有可能包括返回一个值. 
            x86-64中,大部分过程间的数据传送是通过寄存器实现的。例如,我们已经看到无数的函数示例,参数在寄存器%rdi、%rsi和其他寄存器中传递。
            当过程P调用过程Q时,P的代码必须首先把参数复制到适当的寄存器中。类似地,当Q返回到p时,P的代码可以访问寄存器%rax中的返回值。
        ```
        - 栈上的局部存储
        ```
            到目前为止我们看到的大多数过程示例都不需要超出寄存器大小的本地存储区域。
            不过有些时候,局部数据必须存放在内存中,常见的情况包括:
            1. 寄存器不足够存放所有的本地数据。
            2. 对一个局部变量使用地址运算符‘&’,因此必须能够为它产生一个地址。
            3. 某些局部变量是数组或结构,因此必须能够通过数组或结构引用被访问到。在描述数组和结构分配时,我们会讨论这个间题。
        ```
        - 寄存器中的局部存储空间
        ```
            寄存器组是唯一被所有过程共享的资源。
            虽然在给定时刻只有一个过程是活动的,我们仍然必须确保当一个过程(调用者)调用另一个过程(被调用者)时,
            被调用者不会覆盖调用者稍后会使用的寄存器值。为此,x86-64采用了一组统一的寄存器使用惯例,所有的过程(包括程序库)都必须遵循。

            根据惯例,寄存器%rbx、frbp和%r12-fr15被划分为被调用者保存寄存器。
            当过程P调用过程Q时,Q必须保存这些寄存器的值,保证它们的值在Q返回到p时与Q被调用时是一样的。
            过程Q保存一个寄存器的值不变,要么就是根本不去改变它,要么就是把原始值压人栈中,改变寄存器的值,然后在返回前从栈中弹出旧值。
            压人寄存器的值会在栈帧中创建标号为“保存的寄存器”的一部分,如图3-25中所示。
            有了这条惯例,P的代码就能安全地把值存在被调用者保存寄存器中(当然,要先把之前的值保存到栈上),调用Q,然后继续使用寄存器中的值,不用担心值被破坏。
        ```
        - 递归过程
        ```
            前面已经描述的寄存器和栈的惯例使得x86-64过程能够递归地调用它们自身。
            每个过程调用在栈中都有它自已的私有空间,因此多个未完成调用的局部变量不会相互影响。
            此外,栈的原则很自然地就提供了适当的策略,当过程被调用时分配局部存储,当返回时释放存储。
        ```
    ###### 小结
    ```
        在本章中， 我们窥视了c语言提供的抽象层下面的东西，以了解机器级编程。 
        通过让编译器产生机 器级程序的汇编代码表 示， 我们了解了编译器和它的优化能力， 
        以及机器、数据类型和指令集。在第 5 章， 我们会看到， 当编写能有效映射到机器上的 程序时， 了解编译器的特性会有所帮助。
        我们还更完整 地了解了程序如何将数据存储在不同的内存区域中。在第 12 章会看到许多 这样的例子，
        应用程序员需要 知道一个程序变量是在运行时栈中，是在某个动态分配的数据结构中，还是全局程序数据的一部分。
        理解程序如何映射到机器上，会让理解这些存储类型之间的区别容易一些。
    ```
---

* 第四章 处理器体系结构
    1. 综述
    ```
        现代微处理器可以称得上是人类创造出的最复杂的系统之一。一块手指甲大小的硅片上， 可以容纳一个完整的高性能处理器、大的高速缓存， 
        以及用来连接到外部设备的逻辑电路。 从性能上来 说， 今天在一块芯片上实现的处理器已经使20年前价值1000万美元、房间那么大的超级计算机相形见绌了。 
        即使是在像手机、导航系统和可编程恒温器这样的日常设备中的嵌入式处理器，也比早期计算机开发者所能想到的强大得多。

        到目前为止，我们看到的计算机系统只限于机器语言程序级。我们知道处理器必须执行一系列指令，每条指令执行某个简单操作， 
        例如两个数相加。指令被编码为由一个或多个字节序列组成的二进制格式。 
        一个处理器支持的指令和指令的字节级编码称为它的指令集体系结构（Instruction-Set Architecture,ISA）

        因此， ISA在编译器编写者和处理器设计人员之间提供了一个概念抽象层，编译器编写者只需要知道允许哪些指令， 
        以及它们是如何编码的；而处理器设计者必须建造出执行这些指令的处理器。
    ```
    2. 列举数据冒险的类型
    ```
        当一条指令更新后面指令会读到的那些程序状态时，就有可能出现冒险。对于 Y86-64 来说，程序状态包括程序寄存器、程序计数器、内存、条件码寄存器和状态寄存器。 
        让我们来看看在提出的设计中每类状态出现冒险的可能性。

        程序寄存器： 我们已经认识这种冒险了。出现这种冒险是因为寄存器文件的读写是在不同的阶段进行的,导致不同指令之间可能出现不希望的相互作用。
        程序计数器： 更新和读取程序计数器之间的冲突导致了控制冒险。当我们的取指阶段逻辑在取下一条指令之前， 
        正确预测了程序计数器的新值时，就不会产生冒险。预测错误的分支和ret指令需要特殊的处理
        内存： 对数据内存的读和写都发生在访存阶段。在一条读内存的指令到达这个阶段之前，前面所有要写内存的指令都已经完成这个阶段了。 
        另外，在访存阶段中写数据的指令和在取指阶段中读指令之间也有冲突，因为指令和数据内存访问的是同一个地址空间。
        条件码寄存器： 在执行阶段中，整数操作会写这些寄存器。条件传送指令会在执行阶段以及条件转移会在访存阶段读这些寄存器。 
        在条件传送或转移到达执行阶段之前，前面所有的整数操作都已经完成这个阶段了。所以不会发生冒险。
        状态寄存器： 指令流经流水线的时候，会影响程序状态。我们采用流水线中的每条指令都与一个状态码相关联的机制，使得当异常发生时，处理器能够有条理地停止.
    ```
    ###### 小结
    ```
        我们已经看到，指令集体系结构，即ISA, 在处理器行为（就指令集合及其编码而言）和如何实现处理器之间提供了一层抽象。 
        ISA提供了程序执行的一种顺序说明，也就是一条指令执行完了，下一条指 令才会开始。

        从IA32指令开始，大大简化数据类型、地址模式和指令编码，我们定义了Y86-64指令集。
        得到的ISA既有RISC指令集的属性，也有CISC指令集的属性。然后，将不同指令组织放到五个阶段中处理, 
        在此，根据被执行的指令的不同，每个阶段中的操作也不相同。据此，我们构造了SEQ处理器，其中每个时钟周期执行一条指令，它会通过所有五个阶段。

        流水线化通过让不同的阶段并行操作，改进了系统的吞吐量性能。在任意一个给定的时刻,多条指令被不同的阶段处理。
        在引入这种并行性的过程中，我们必须非常小心，以提供与程序的顺序执行相同的程序级行为。 
        通过重新调整SEQ各个部分的顺序，引入流水线，我们得到SEQ+,接着添加流水线寄存器， 
        创建岀PIPE一流水线。然后，添加了转发逻辑，加速了将结果从一条指令发送到另一条指令， 
        从而提高了流水线的性能。有几种特殊情况需要额外的流水线控制逻辑来暂停或取消一些流水线阶段。

        我们的设计中包括了一些基本的异常处理机制,在此,保证只有到异常指令之前的指令会影响程序员可见的状态。
        实现完整的异常处理远比此更具挑战性。在采用了更深流水线和更多并行性的系统中，要想正确处理异常就更加复杂了。

        在本章中，我们学习了有关处理器设计的几个重要经验：
            1.  管理复杂性是首要问题。想要优化使用硬件资源，在最小的成本下获得最大的性能。为了实现这个目的， 
            我们创建了一个非常简单而一致的框架，来处理所有不同的指令类型。有了这个框架，就能够在处理不同指令类型的逻辑中共享硬件单元。
            2. 我们不需要直接实现ISA.ISA的直接实现意味着一个顺序的设计。为了获得更高的性能,我们想运用硬件能力以同时执行许多操作， 
            这就导致要使用流水线化的设计。通过仔细的设计和分析，我们能够处理各种流水线冒险，因此运行一个程序的整体效果， 
            同用ISA模型获得的效果完全一致。
            3. 硬件设计人员必须非常谨慎小心。一旦芯片被制造出来，就几乎不可能改正任何错误了。一开始就使设计正确是非常重要的。 
            这就意味着要仔细地分析各种指令类型和组合，甚至于那些看上去没有意义的情况，例如弹出值到栈指针。
            必须用系统的模拟测试程序彻底地测试设计。在开发PIPE的控制逻辑中，我们的设计有个细微的错误， 
            只有通过对控制组合的 仔细而系统的分析才能发现。
    ```
---

* 第五章 优化程序性能
    1. 综述
    ```
        写程序最主要的目标就是使它在所有可能的情况下都正确工作。
        一个运行得很快但是给岀错误结果的程序没有任何用处。
        程序员必须写出清晰简洁的代码,这样做不仅是为了自己能够看懂代码，
        也是为了在检查代码和今后需要修改代码时，其他人能够读懂和理解代码。

        另一方面，在很多情况下，让程序运行得快也是一个重要的考虑因素。如果一个程序要实时地处理视频帧或者网络包，
        一个运行得很慢的程序就不能提供所需的功能。当一个计算任务的计算量非常大，需要执行数日或者数周， 
        那么哪怕只是让它运行得快20%也会产生重大的影响。本章会探讨如何使用几种不同类型的程序优化技术，使程序运行得更快。

        编写高效程序需要做到以下几点：第一，我们必须选择一组适当的算法和数据结构。第二，我们必须编写岀编译器能够有效优化以转换成高效可执行代码的源代码。
        对于这第二点，理解优化编译器的能力和局限性是很重要的。编写程序方式中看上去只是一点小小的变动， 
        都会引起编译器优化方式很大的变化。有些编程语言比其他语言容易优化。C语言的有些特性，例如执行指针运算和强制类型转换的能力，
        使得编译器很难对它进行优化。程序员经常能够以一种使编译器更容易产生高效代码的方式来编写他们的程序。
        第三项技术针对处理运算量特别大的计算，将一个任务分成多个部分,这些部分可以在多核和多处理器的某种组合上并行地计算。
        我们会把这种性能改进的方法推迟到第12章中去讲。即使是要利用并行性，每个并行的线程都以最高性能执行也是非常重要的， 
        所以无论如何本章所讲的内容也还是有意义的。

        在程序开发和优化的过程中，我们必须考虑代码使用的方式，以及影响它的关键因素。
        通常，程序员必须在实现和维护程序的简单性与它的运行速度之间做出权衡。在算法级上，几分钟就能编写一个简单的插入排序，
        而一个高效的排序算法程序可能需要一天或更长的时间来实现和优化。在代码级上，
        许多低级别的优化往往会降低程序的可读性和模块性，使得程序容易出错，并且更难以修改或扩展。 
        对于在性能重要的环境中反复执行的代码，进行大量的优化会比较合适。一个挑战就是尽管做了大量的变化，
        但还是要维护代 码一定程度的简洁和可读性。

        我们描述许多提高代码性能的技术。理想的情况是，编译器能够接受我们编写的任何代码， 
        并产生尽可能高效的、具有指定行为的机器级程序。现代编译器釆用了复杂的分析和优化形式， 
        而且变得越来越好。然而，即使是最好的编译器也受到妨碍优化的因素(optimization blocker)的阻碍，
        妨碍优化的因素就是程序行为中那些严重依赖于执行环境的方面。程序员必须编写容易优化的代码，以帮助编译器。

        程序优化的第一步就是消除不必要的工作，让代码尽可能有效地执行所期望的任务。
        这包括消除不必要的函数调用、条件测试和内存引用。这些优化不依赖于目标机器的任何具体属性。

        为了使程序性能最大化，程序员和编译器都需要一个目标机器的模型，指明如何处理指令，以及各个操作的时序特性。
        例如，编译器必须知道时序信息，才能够确定是用一条乘法指令，还是用移位和加法的某种组合。
        现代计算机用复杂的技术来处理机器级程序，并行地执行许多指令，执行顺序还可能不同于它们在程序中出现的顺序。
        程序员必须理解这些处理器是如何工作的，从而调整他们的程序以获得最大的速度.基于Intel和AMD处理器最近的设计， 
        我们提出了这种机器的一个高级模型。我们还设计了一种图形数据流(data-flow)表示法， 
        可以使处理器对指令的执行形象化，我们还可以利用它预测程序的性能。

        对于新手程序员来说，不断修改源代码，试图欺骗编译器产生有效的代码，看起来很奇怪，但这确实是编写很多高性能程序的方式。
        比较于另一种方法一一用汇编语言写代码，这种间接的方法具有的优点是：虽然性能不一定是最好的，但得到的代码仍然能够在其他机器上运行。
    ```
    2. 优化编译器 的能力和局限性
        - 综述
        ```
            现代编译器运用复杂精细的算法来确定一个程序中计算的是什么值，以及它们是被如何使用的。 
            然后会利用一些机会来简化表达式，在几个不同的地方使用同一个计算，以及降低一个给定的计算必须被执行的次数。 
            大多数编译器，包括 GCC,向用户提供了一些对它们所使用的优化的控制。就像在第3章中讨论过的，最简单的控制就是指定优化级别。

            编译器并不清楚程序的意图以及一些过程(函数)何时会被调用.这一系列原因使得编译器只能保守的进行优化,也就是编译器优化程序性能有一定的局限性.
        ```
    3. 理解现代处理器
        - 综述
        ```
            为了理解改进性能的方法，我们需要理解现代处理器的微体系结构。由于大量的晶体管可以被集成到一块芯片上， 
            现代微处理器采用了复杂的硬件，试图使程序性能最大化。带来的一个后果就是处理器的实际操作与通过观察机器级程序所察觉到的大相径庭。 
            在代码级上，看上去似乎是一次执行一条指令，每条指令都包括从寄存器或内存取值，执行一个操作，并把结果存回到一个寄存器或内存位置。 
            在实际的处理器中，是同时对多条指令求值的，这个现象称为 [指令级并行]。在某些设计中，可以有100或更多条指令在处理中。
            釆用一些精细的机制来确保这种并行执行的行为，正好能获得机器级程序要求的顺序语义模型的效果。 
            现代微处理器取得的了不起的功绩之一是：它们采用复杂而奇异的微处理器结构，其中，多条指令可以并行地执行，同时又呈现出一种简单的顺序执行指令的表象。

            虽然现代微处理器的详细设计超出了本书讲授的范围,对这些微处理器运行的原则有一般性的了解就足够能够理解它们如何实现指令级并行。 
            我们会发现两种下界描述了程序的最大性能。当一系列操作必须按照严格顺序执行时，就会遇到延迟界限(latency bound),
            因为在下一条指令开始之前，这条指令必须结束。当代码中的数据相关限制了处理器利用指令级并行的能力时，延迟界限能够限制程序性能。
            吞吐量界限(throughput bound)刻画了处理器功能单元的原始计算能力。这个界限是程序性能的终极限制。
        ```
        - 整体操作
        ```
            我们假想的处理器设计是不太严格地基于近期的Intel处理器的结构.这些处理器在工业界称为超标量(superscalar),
            意思是它可以在每个时钟周期执行多个操作，而且是乱序的(out-of-order),意思就是指令执行的顺序不一定要与它们在机器级程序中的顺序一致。 
            整个设计有两个主要部分：指令控制单元(Instruction Control Unit, ICU)和执行单元(Execution Unit, EU).
            前者负责从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作；而后者执行这些操作。
            和第4章中研究过的按序(in-order)流水线相比，乱序处理器需要更大、更复杂的硬件，但是它们能更好地达到更高的指令级并行度。
            即试图以空间换时间

            指令译码逻辑接收实际的程序指令，并将它们转换成一组基本操作(有时称为微操作)。每个这样的操作都完成某个简单的计算任务， 
            例如两个数相加，从内存中读数据，或是向内存写数据。对于具有复杂指令的机器,比如 x86 处理器 , 
            一条指令可以被译码成多个操作。关于指令如何被译码成操作序列的细节，不同的机器都会不同，这个信息可谓是高度机密。
            幸运的是，不需要知道某台机器实现的底层细节，我们也能优化自己的程序。

            addq %rax,%rdx会被转化成一个操作。另一方面，一条包括一个或者多个内存引用的指令，例如addq %rax,8(%rdx)会产生多个操作， 
            把内存引用和算术运算分开。这条指令会被译码成为三个操作：一个操作从内存中加载一个值到处理器中,
            一个操作将加载进来的值加上寄存器％ 0X 中的值，而一个操作将结果存 回到内存。这种译码逻辑对指令进行分解， 
            允许任务在一组专门的硬件单元之间进行分割。这些单元可以并行地执行多条指令的不同部分。

            总的来说，重新结合变换能够减少计算中关键路径上操作的数量，通过更好地利用功能单元的流水线能力得到更好的性能。 
            大多数编译器不会尝试对浮点运算做重新结合，因为这些运算不保证是可结合的。当前的GCC版本会对整数运算执行重新结合， 
            但不是总有好的效果。通常，我们发现循环展开和并行地累积在多个值中，是提高程序性能的更可靠的方法。
        ```
        - 优化合并代码的结果小结
        ```
            使用多项优化技术，我们获得的CPE已经接近于0. 50和1.00的吞吐量界限，只受限于功能单元的容量。
            与原始代码相比提升了10〜20倍，且使用普通的C代码和标准编译器就获得了所有这些改进。
            重写代码利用较新的SIMD指令得到了将近4倍或8倍的性能提升。比如单精度乘法，CPE从初值11.14降到了0.06,整体性能提升超过180倍。
            这个例子说明现代处理器具有相当的计算能力，但是我们可能需要按非常程式化的方式来编写程序以便将这些能力诱发出来。
        ```
        - 一些限制因素
        ```
            循环并行性的好处受汇编代码描述计算的能力限制。如果我们的并行度力超过了可用的寄存器数量，
            那么编译器会诉诸溢出(spilling),将某些临时值存放到内存中，通常是在运行时堆栈上分配空间。

            一旦编译器必须要诉诸寄存器溢出，那么维护多个累积变量的优势就很可能消失。
            幸运的是，x86-64有足够多的寄存器，大多数循环在出现寄存器溢岀之前就将达到吞吐量限制。
        ```
        - 分支预测和预测错误处罚
        ```
            在一个使用投机执行(speculative execution)的处理器中，处理器会开始执行预测的分支目标处的指令。
            它会避免修改任何实际的寄存器或内存位置，直到确定了实际的结果。如果预测正确，那么处理器就会“提交”投机执行的指令的结果，把它们存储到寄存器或内存。
            如果预测错误，处理器必须丢弃掉所有投机执行的结果，在正确的位置，重新开始取指令的过程。
            这样做会引起预测错误处罚，因为在产生有用的结果之前，必须重新填充指令流水线。
        ```
        - 理解内存性能
        ```
            到目前为止我们写的所有代码，以及运行的所有测试，只访问相对比较少量的内存。
            例如，我们都是在长度小于1000个元素的向量上测试这些合并函数，数据量不会超过8000个字节。
            所有的现代处理器都包含一个或多个高速缓存（cache）存储器，以对这样少量的存储器提供快速的访问。
            本节会进一步研究涉及加载（从内存读到寄存器）和存储（从寄存器写到内存）操作的程序的性能，只考虑所有的数据都存放在高速缓存中的情况。
            在第6章，我们会更详细地探究高速缓存是如何工作的，它们的性能特性，以及如何编写充分利用高速缓存的代码。

            现代处理器有专门的功能单元来执行加载和存储操作，这些单元有内部的缓冲区来保存未完成的内存操作请求集合。

            1. 加载的性能
            一个包含加载操作的程序的性能既依赖于流水线的能力，也依赖于加载单元的延迟。
            2. 存储的性能
            在迄今为止所有的示例中，我们只分析了大部分内存引用都是加载操作的函数，也就是从内存位置读到寄存器中。
            与之对应的是存储(store)操作，它将一个寄存器值写到内存。这个操作的性能，尤其是与加载操作的相互关系，包括一些很细微的问题。
            与到目前为止我们已经考虑过的其他操作不同，存储操作并不影响任何寄存器值。因此，就其本性来说，一系列存储操作不会产生数据相关。
            只有加载操作会受存储操作结果的影响，因为只有加载操作能从由存储操作写的那个位置读回值。
            2. 应用：性能提高技术
                虽然只考虑了有限的一组应用程序，但是我们能得出关于如何编写高效代码的很重要的经验教训。我们已经描述了许多优化程序性能的基本策略：
                1）高级设计。为遇到的问题选择适当的算法和数据结构。要特别警觉，避免使用那些会渐进地产生糟糕性能的算法或编码技术。
                2）基本编码原则。避免限制优化的因素，这样编译器就能产生高效的代码。
                    •消除连续的函数调用。在可能时，将计算移到循环外。考虑有选择地妥协程序的模块性以获得更大的效率。
                    •消除不必要的内存引用。引入临时变量来保存中间结果。只有在最后的值计算出来时，才将结果存放到数组或全局变量中。
                3)低级优化。结构化代码以利用硬件功能。
                    •展开循环，降低开销，并且使得进一步的优化成为可能。
                    •通过使用例如多个累积变量和重新结合等技术，找到方法提高指令级并行。
                    •用功能性的风格重写条件操作，使得编译采用条件数据传送。
            最后要给读者一个忠告，要警惕，在为了提高效率重写程序时避免引入错误。在引入新变量、改变循环边界和使得代码整体上更复杂时，很容易犯错误。
            一项有用的技术是在优化函数时，用检查代码来测试函数的每个版本，以确保在这个过程没有引入错误。检查代码对函数的新版本实施一系列的测试，
            确保它们产生与原来一样的结果。对于高度优化的代码，这组测试情况必须变得更加广泛，因为要考虑的情况也更多。
            例如，使用循环展开的检查代码需要测试许多不同的循环界限，保证它能够处理最终单步迭代所需要的所有不同的可能的数字。

        ```
    ###### 小结
    ```
        虽然关于代码优化的大多数论述都描述了编译器是如何能生成高效代码的，但是应用程序员有很多方法来协助编译器完成这项任务。
        没有任何编译器能用一个好的算法或数据结构代替低效率的算法或数据结构，因此程序设计的这些方面仍然应该是程序员主要关心的。
        我们还看到妨碍优化的因素，例如内存别名使用和过程调用，严重限制了编译器执行大量优化的能力。
        同样，程序员必须对消除这些妨碍优化的因素负主要的责任。这些应该被看作好的编程习惯的一部分，因为它们可以用来消除不必要的工作。

        基本级别之外调整性能需要一些对处理器微体系结构的理解，描述处理器用来实现它的指令集体系结构的底层机制。
        对于乱序处理器的情况，只需要知道一些关于操作、容量、延迟和功能单元发射时间的信息，就能够基本地预测程序的性能了。

        我们研究了一系列技术，包括循环展开、创建多个累积变量和重新结合，它们可以利用现代处理器提供的指令级并行。
        随着对优化的深入，研究产生的汇编代码以及试着理解机器如何执行计算变得重要起来。
        确认由程序中的数据相关决定的关键路径，尤其是循环的不同迭代之间的数据相关，会收获良多。
        我们还可以根据必须要计算的操作数量以及执行这些操作的功能单元的数量和发射时间，计算一个计算的吞吐量界限。

        包含条件分支或与内存系统复杂交互的程序，比我们最开始考虑的简单循环程序，更难以分析和优化。
        基本策略是使分支更容易预测，或者使它们很容易用条件数据传送来实现。我们还必须注意存储和加载操作。
        将数值保存在局部变量中，使得它们可以存放在寄存器中，这会很有帮助。

        当处理大型程序时，将注意力集中在最耗时的部分变得很重要。代码剖析程序和相关的工具能帮助我们系统地评价和改进程序性能。
        我们描述了GPROF,一个标准的Unix剖析工具。
    ```

--- 

* 第六章 存储器层次结构
